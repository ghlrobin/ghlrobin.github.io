---
title: "[boostcamp AI Tech / Level 1 - AI Math] Day 4 - CNN 첫걸음"
date: 2022-09-22 10:00:00 + 0900
categories: [boostcamp AI Tech, Level 1 - AI Math]
tags: [boostcamp, ai math, level 1, week 1]	# TAG names should always be lowercase
math: true
---


- [Convolution 연산 이해하기](#convolution-연산-이해하기)
  - [기존에 배운 MLP 연산](#기존에-배운-mlp-연산)
  - [CNN 연산](#cnn-연산)
- [다양한 차원에서의 Convolution](#다양한-차원에서의-convolution)
- [2차원 Convolution 연산 이해하기](#2차원-convolution-연산-이해하기)
- [Convolution 연산의 역전파 이해하기](#convolution-연산의-역전파-이해하기)

## Convolution 연산 이해하기

### 기존에 배운 MLP 연산

* 지금까지 배운 다층신경망(MLP)은 fully connected 구조였기 때문에 $h_i$를 구할 때 $W_i$가 항상 필요.
  * 학습을 해야하는 parapeter의 숫자가 너무 커지게 됨.

$$
h_{i} = \sigma\left( \sum_{j=1}^{p} W_{ij}x_{j} \right)
$$ 

### CNN 연산

![](/assets/img/boostcamp/2022-09-22-14-21-47.png)

$$
h_{i} = \sigma\left( \sum_{j=1}^{p} V_{ij}x_{j} \right)
$$ 

* convolution 연산은 기존의 $W$ 가중치 행렬을 사용하지 않고 $V$ 라는 kernel 행렬을 활용함 (선형변환의 한 종류)
* 고정된 kernel을 입력 백터 $x$가 움직이며 계산이 됨
* Parameter size를 많이 줄일 수 있음
* Convolution 연산의 수학적인 의미는 커널을 신호(signal)를 이용해 국소적(locally)으로 증폭 또는 감소시켜서 정보를 추출 또는 필터링하닌 것.

$$
\begin{aligned}
\text{continuous} \quad [f * g](x) = \int_{\mathbb{R}^d}f(z)g(x + z)dz = \int_{\mathbb{R}}f(x + z)g(z)dz = [g * f](x) \\
\text{discrete} \quad [f * g](x) = \sum_{a\in\mathbb{Z}^{d}}f(a)g(i + a) = \sum_{a\in\mathbb{Z}^{d}}f(i + a)g(a) = [g * f](i) \quad\quad
\end{aligned}
$$  

* CNN에서 사용되는 연산은 사실 convolution이 아니고 cross-correlation이라고 부름.
* kerenl의 2가지 특징:
  * Translation invariant: 정의역 내에서 움직여도 변하지 않음
  * locality: 주어진 신호를 국소적으로 적용
* 영상처리에서 convolution의 역활을 [확인](http://setosa.io/ev/image-kernels)해보자

- - -
## 다양한 차원에서의 Convolution

![](/assets/img/boostcamp/2022-09-22-14-41-09.png)

* 데이터의 성격에 따라 사용하는 커널이 달라짐
* $i,~j,~k$가 바뀌어도 커널 $f$의 값은 바뀌지 않는다.

- - -

## 2차원 Convolution 연산 이해하기

![](/assets/img/boostcamp/2022-09-22-14-47-40.png)

* 2D-Conv 연산은 커널을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조다.
* 각 행렬값을 입력값에 elementw-wise 곱셈을 해서 연산을 한다
* 출력의 크기가 당연히 줄어든다.

$$
\begin{aligned}
O_{H} = H - K_{H} + 1 \; \\ 
O_{W} = W - K_{W} + 1
\end{aligned}
$$

e.g. 입력 데이터의 크기가 28 x 28이고 3 x 3 커널로 convolution되면 26 x 26이 된다.

* 채널이 여럭개인 2차원 입력의 경우 2차원 Convolution을 채널 개수만큼 적용한다고 다 더해서 출력한다
* 3차원부터는 행렬이 아닌 텐서(Tensor)라 부른다.

![](/assets/img/boostcamp/2022-09-22-14-56-53.png)

* 만약에 채널이 여러개인 출력을 원한다면 커널을 그만큼 적용하면 된다.

![](/assets/img/boostcamp/2022-09-22-14-59-03.png)

- - -

## Convolution 연산의 역전파 이해하기

* Convolution 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 convolution 연산이 나오게 된다.

$$
\begin{aligned}
\begin{matrix}
    \frac{\partial}{\partial x}[f * g](x) &=& \frac{\partial}{\partial x}\int_{\mathbb{R}^{d}}f(y)g(x-y) dy \\
    &=& \int_{\mathbb{R}^{d}}f(y)\frac{\partial g}{\partial x}(x - y)dy \\
    &=& [f * g'](x)
\end{matrix}
\end{aligned}
$$  

