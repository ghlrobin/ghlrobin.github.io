---
title: "[boostcamp AI Tech][PyTorch] Lecture 8: Multi-GPU 학습"
date: 2022-09-29 12:00:00 + 0900
categories: [boostcamp AI Tech, Week 2 - PyTorch]
tags: [boostcamp, pytorch, level 1, week 2] # TAG names should always be lowercase
math: true
---

- [Going into the Lecture](#going-into-the-lecture)
- [개념 정리](#개념-정리)
- [Model Parallelism](#model-parallelism)
- [Data Parallelism](#data-parallelism)

# Going into the Lecture

- 예전에는 어떻게 GPU를 덜 사용할까 고민을 했다면 이제는 얼마나 GPU를 많이 + 잘 사용해서 큰 모델을 학습 시킬까가 초점이다
- 오늘날은 딥러닝은 엄청난 데이터와의 싸움을 하고 있다

# 개념 정리

- Single GPU는 GPU 1개를 때, multi GPU는 GPU를 두 개 이상사용할 때를 말한다
- 우리가 Node(System)를 사용한다고 할때는 1대의 컴퓨터를 뜻한다
- Single Node single GPU: 평소 데스크탑 컴퓨터
- Single Node Multi GPU: 컴퓨터에 GPU가 여러 장 들어있을 때
- Multi Node Multi GPU: 대용량 서버에서 하듯이 여러 컴퓨터에 여러 GPU
- NVIDIA에서 이런 Multi GPU를 지원해주기 위해 TensorRT 8.0라는 도구를 공개했다.

# Model Parallelism

- 다중 GPU에 학습을 분산하는 2가지 방법이 있다
  1. 모델 병렬화: Alexnet 부터 사용했었음. 하지만 병목, 파이프라인의 어려움 등으로 인해 모델 병렬을 어려운 과제이다. 그렇게 흔하지는 않다
  2. 데이터 병렬화

![](/assets/img/boostcamp/2022-09-30-20-06-41.png)

# Data Parallelism

- 데이터를 나눠 GPU에 할당한 후 결과의 평균을 취하는 방법이다
- minibatch 수식과 유사한데 한번에 여러 GPU에서 수행한다

![](/assets/img/boostcamp/2022-09-30-20-10-42.png)

- PyTorch에서 2가지 Data Parallel 방식을 제공한다

- `DataParallel`
   - 데이터를 GPU들로 분배한 후 평균을 취한다
   - GPU 사용 뷸균형 문제 발생, batch 사이즈 감소(main GPU가 병목)
     - coodinating 하는 main GPU가 메모리가 부족하다
   - Global Iterpreter Lock 문제가 생긴다

```python
# DataParallel
parallel_model = torch.nn.DataParallel(model) # Encapsulate the model (이게 전부)

predictions = parallel_model(inputs) # Forward pass on multi-GPUs
loss = loss_function(predictions, labels) # Compute loss fn
loss.mean().backward() # Average GPU-losses + backward pass
optimizer.step() # Optimizer step
predictions = parallel_model(inputs) # Forward pass with new parameters
```

- `DistributedDataParallel` 
  - `DataParallel`의 단점을 해결하려고 한다
  - 각 CPU마다 process를 생성하여 개별 GPU에 할당
  - 즉 모으는 작업이 없고 각각 연산을 진행하고 결과만을 합쳐 평균은 낸다.
  - 다시 말해 기본적으로 DataParallel로 하지만 개별적으로 연산의 평균을 낸다.

```python
sampler = torch.utils.data.distributed.DistributedSampler(train_data)
shuffle = False
pin_memory = True

train_loader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=shuffle, pin_memory=pin_memory, num_workers=3,sampler=sampler) 
# num_workers = GPU x 4


def main():
    n_gpu = torch.cuda.device_count()
    torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, ))

def main_worker(gpu, n_gpus):

    image_size = 224
    batch_size = 512
    num_worker = 8
    epoch = ...
    
    batch_size = int(batch_size/n_gpus)
    num_worker = int(num_worker/n_gpus)

    # set multiprocessing protocol

    model = MODEL

    torch.cuda.set_device(gpu)
    model = model.cuda(gpu)
    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu]) # Distributed DataParallel 정의

from multiprocessing import Pool

def f(x): # python의 멀티프로세싱 코드
    return # your function

if __name__ == '__main__':
    with Pool(4) as p:
        print(p.map(f, [1,2,3]))
```

-----------------------------------


