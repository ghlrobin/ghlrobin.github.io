---
title: "[boostcamp AI Tech][DL Basic] Lecture 6: Computer Vision Applications"
date: 2022-10-03 14:00:00 + 0900
categories: [boostcamp AI Tech, Week 3 - DL Basic]
tags: [boostcamp, dl basic, level 1, week 3] # TAG names should always be lowercase
math: true
---

- [Going into the Lecture](#going-into-the-lecture)

# Going into the Lecture

- We explore the ways in which Computer Vision uses CNN
  - Semantic segmentation
  - Object detection.

# Semantic Segmentation

![](/assets/img/boostcamp/2022-10-03-23-24-29.png)

- Labeling pixel by pixel
- Also called dense classification or per-pixel classification
- Used in autonomous driving.

## Fully Convolutional Network

- Aim to remove the fully connected layer through convolutionalization.

![](/assets/img/boostcamp/2022-10-03-23-29-35.png)

- doesn't actually affect the number of parameters but...
- transforming fully connected layers into convolution layers enables a classification net to output a **heat map**.
  
![](/assets/img/boostcamp/2022-10-03-23-30-45.png)

- While FCN can run with inputs of any size, the output dimensions are typically reduced by subsampling
- So we need a way to connect the coarse output to the dense pixels. i.e. upsampling, deconvolution, unpooling, convolution transpose.

## Deconvolution (conv transpose)

![](/assets/img/boostcamp/2022-10-03-23-35-06.png)

- technically you can't actually get back the data by deconvolution (it's not an inverse of convolution) but you can atleast get the size that you want.

# Object Detection

## R-CNN

![](/assets/img/boostcamp/2022-10-03-23-38-11.png)

- R-CNN does this:
1. Take an input image
2. extract around 2000 region proposals using Selective Search
3. Compute features for each proposal (using AlexNet)
4. Classify with linear SVMs.

- Basically a brute force method
- Not perfect
- Slow
- But Works

## SPPNet (Spatial Pyramid Pooling)

![](/assets/img/boostcamp/2022-10-03-23-48-45.png)

- In R-CNN, the number of crop/warp is usually over 2000 meaning that CNN must run more than 2000 times (CPU takes 59s per image)
- However, in SPPNet, CNN runs once on the entire image

![](/assets/img/boostcamp/2022-10-03-23-50-01.png)

## Fast R-CNN

![](/assets/img/boostcamp/2022-10-03-23-51-16.png)

1. Take an input and a set of object proposals
2. Generate a conv feature map
3. for each bounding box, get a fixed-length feature vector from ROI pooling layer and fcs
4. Outputs two information
   1. k+1 class labels
   2. bounding box locations

![](/assets/img/boostcamp/2022-10-03-23-52-58.png)

## Faster R-CNN

- Faster R-CNN = Fast R-CNN + Region Proposal Network

![](/assets/img/boostcamp/2022-10-03-23-54-04.png)

Regional Proposal Network is a FCN which outputs K*(4+2) sized vectors
- Input an image of any size
- Generate conv feature map
- Map to a lower-dimensional feature
- Output objectness score and bounding box

## YOLO (You Only Look Once)

![](/assets/img/boostcamp/2022-10-04-09-33-13.png)

- YOLO(v1) is an extremely fast object detection algorithm
  - baseline: 45fps / smaller version: 155fps
- It simultaneously predicts multiple bounding boxes and class probabilities
  - No explicit bounding box sampling (compared with Faster R-CNN).

![](/assets/img/boostcamp/2022-10-04-09-33-35.png)

- Given an image, YOLO divides it into S x S grid
  - If the center of an object falls into the grid cell, that grid cell is responsible for detection
- Each cell predicts B bounding boxes (B = 5)
  - Each bounding box predicts
    - box refinement (x / y / w / h)
    - confidence (of objectness)
- Each cell predicts C class probabilities
- In total, it becomes a tensor with S x S x (B*5 + C) size
  - S x S: number of cells of the grid
  - B*5: B bounding boxes with offsets(x,y,w,h) and confidence
  - C: number of classes.


-------------------------------


