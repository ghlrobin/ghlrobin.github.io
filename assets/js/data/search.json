[ { "title": "[boostcamp AI Tech][Data Viz] Lecture 01: Introduction to Visualization", "url": "/posts/01-introduction-to-visualization/", "categories": "boostcamp AI Tech, Week 3 - Data Visualization", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-05 10:00:00 +0900", "snippet": " 데이터 시각화란 무엇일까?데이터 시각화란 무엇일까?다양한 요소가 포함된 작업이다 목적: 왜 시각화를 하나요? 독자: 시각화 결과는 누구를 대상으로 하나요? 데이터: 어떤 데이터를 시각화할 것인가요? 스토리: 어떤 흐름으로 인사이트를 전달할 것인가요? 방법: 전달하고자 하는 내용에 맞게 효과적인 방법을 사용하고 있나요? 디자인: UI에서 만족스러운 디자인을 가지고 있나요?데이터 이해하기 데이터 시각화를 위해서는 데이터가 우선적으로 필요하고 시각화를 진행할 데이터를 데이터셋 관점(global)에서 또는 개별 데이터의 관점(local)에서 정리할지를 정해야 한다.데이터셋의 종류 요즘에는 수많은 데이터셋이 존재를 한다. 정형 데이터 시계열 데이터 지리 데이터 관계형(네티워크) 데이터 계층적 데이터 다양한 비정형 데이터 대표적으로 데이터의 종류는 4가지로 분류한다 수치형(numerical) 연속형(continuous): 길이, 무게, 온도 등 이산형(discrete): 주사위 눈금, 사람 수 등 범주형(categorical) 명목형(nominal): 형액형, 종교 등 순서형(ordinal): 학년, 벌점, 등급 등 정형 데이터 테이블 형태로 제공되는 데이터이며 일반적으로 csv, tsv 파일로 제공이 된다 Row가 데이터 1개 item Column은 attribute(feature) 가장 쉽게 시각화할 수 있는 데이터셋이다 통계적 특성과 feature 사이 관계 데이터 간 관계 데이터 간 비교 가장 많이 다루게 될 데이터셋이다.시계열 데이터 (Timeseries) 시간 흐름에 따른 데이터를 time-series 데이터라고 한다 기온, 주가 등 정형데이터와 음성, 비디오와 같은 비정형 데이터가 존재 한다 시간 흐름에 따른 추세(Trend), 계절성(Seasonality), 주기성(Cycle)등을 살필 수 있다.지리 데이터 지도 정보와 보고자 하는 정보 간의 조화 중요와 지도 정보를 단순화 시키는 경우도 존재한다 거리, 경로, 분포 등 다양한 실사용이 가능하다 실제로 어떻게 사용하는지가 중요하다.관계 데이터 객체와 객체 간의 관계를 시각화한다 Graph Visualization / Network Visualization 객체는 Node로, 관계는 link로 표현을 한다 크기, 색, 수 등으로 객체와 관계의 가중치를 표현을 한다 휴리스틱하게 노드 배치를 구성한다계층적 데이터 관게 중에서도 포함관계가 분명한 데이터이다 네트워크 시각화로도 표현 가능 Tree, Treemap, Sunburst 등으로 표현이 가능하다시각화 이해하기 A mark is a basic graphical element in an image (points, lines, areas) A visual channel is a way to control the apperance of marks, independent of the dimensionality of the geometric primitive position(horizontal, vertical or both), color, shape, tilt, and size all have an impact on visualization 전주의적 속성(pre-attentive attribute) 주의를 주지 않아도 인지하게 되는 요소들을 말한다 시각적으로 다양한 전주의적 속성이 존재한다 하지만 동시에 사용하면 인지하기가 어렵다 적절하게 사용할 때, 시각적 분리(visual pop-out) " }, { "title": "[boostcamp AI Tech][Day 12] Week 3 Sleepy", "url": "/posts/day-12/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ml basic, level 1, week 3, day in review", "date": "2022-10-04 23:00:00 +0900", "snippet": "Day in ReviewIt’s up to me how to best use the resources around me and I have to act as such. Whether it be time provided for mentor session, the time I have to study and the time I have to rest. I guess a lot of it is to do with time. And it seems right now that I don’t have enough of it. My To-Do list is getting full while I can only do so much. Again, I just need to keep my head down and do things one at a time.Today, I was less productive than yesterday but it wasn’t so bad. I had a mentor session where our mentor shared the tools he uses as a developer. Then I wasted some time (a fair bit) in gather.town where we eventually realised that it is slightly above our ability to make a good custom map." }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 10: Generative Models Part 2", "url": "/posts/10-generative-2/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-04 22:00:00 +0900", "snippet": " Maximum Likelihood LearningMaximum Likelihood Learning Given a training set of examples, we can cast the generative model learning process as finding the best-approximating density model from the model family Then, how can we evalutate the goodness of the approximation?" }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 9: Generative Models Part 1", "url": "/posts/09-generative-1/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-04 13:00:00 +0900", "snippet": " Learning a Generative Model Example Independence Conditional Independence Autoregressive Model (AR Model) NADE: Neural Autoregressive Density Estimator Summary of AR ModelsLearning a Generative Model Suppose that we are given images of dogs We want to learn a probability distribution $p(x)$ such that Generation: if we sample $\\tilde{x} \\sim p(x)$, $\\tilde{x}$ should look like a dog Density estimation: $p(x)$ should be high if $x$ looks like a dog, and low otherwise This is also known as explicit models Then, how can we represent $p(x)$? Example When modeling a single pixel of an RGB image we have $(r,g,b) \\sim p(R,G,B)$. The number of possible cases is 256 x 256 x 256 but the parameters we need to specify is 256 x 256 x 256 - 1. We need one less because the last number is dependent upon the rest.Independence Suppose we have $X_1, …, X_n$ of $n$ binary pixels (black or white). then the number of cases is $2^n$ and the parameters we need is $2^n - 1$ This shows that it’s impossible to even model a basic image because the number of parameters is so large. But if $X_1, …, X_n$ are independent, then by independence, $P(X_1,…,X_n) = P(X_1)P(X_2)…P(X_n)$ Then the number of cases is still $2^n$ but the number of parameters is simply $n$ However, this doesn’t mean much if not, anything. So we want to find a middle ground, that is Conditional IndependenceConditional Independence There are three important rules Chain rule: $p(x_1,…,x_n) = p(x_1)p(x_2 x_1)p(x_3 x_2,x_1)…p(x_n x_{n-1},…,x_1)$ Bayes’ rule: $p(x y) = \\frac{p(x,y)}{p(y)}$ Condtional Independence: if $x \\perp y z$, then $p(x y,z) = p(x z)$ Then using the chain rule $P(x_1,…,x_n) = P(x_1)P(x_2|x_1)P(x_3|x_2,x_1)…P(x_n|x_{n-1},…,x_1)$. Then calculating the number of parameters… $P(X_1)$: 1 parameters $P(X_2 X_1)$: 2 parameters (one per $X_1 = 0, 1$) $P(X_3 X_1, X_2)$: 2 parameters Hence the total is $1 + 2 + 2^2 + … + 2^{n-1} = 2^n - 1$ which is the same as beforeNow applying the Markov assumption, we get $p(x_1,…,x_n) = p(x_1)p(x_2|x_1)p(x_3|x_2)…p(x_n|x_{n-1})$ which has $2n-1$ parameters By leveraging the Markov assumption, we get exponential reduction on the number of parameters Autoregressive models leverge this conditional independency.Autoregressive Model (AR Model) Suppose we have 28 x 28 binary pixels. Our goal is to learn $P(X) = P(X_1,…,X_{789})$ over $X \\in {0, 1}^{784}$ Then, how can we parametrize $P(X)$? We use the chain rule to factor the joint distribution $P(X_{1:784} = P(X_1)P(X_2 X_1)P(X_3 X_2)…$ This is called an autoregressive model Note that we need an ordering (e.g. raster scan order) of all random variables. NADE: Neural Autoregressive Density Estimator NADE is an explicit model that can compute the density of the given inputs How can we compute the density of the given image? Suppose that we have a binary image with 784 binary pixels Then, the joint probability is computed by $p(x_{1:784} = p(x_1)p(x_2 X_1)p(x_3 X_2)…p(x_784 x_{1:783})$ In case of modeling continuous random variables, a mixture of Gaussian (MoG) can be used.Summary of AR Models Easy to sample from Easy to compute probability Easy to extend to continuous variables." }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 8: Transformer", "url": "/posts/08-transformer/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-04 11:00:00 +0900", "snippet": " Sequential ModelTransformer Transformer is the first sequence transduction model based entirely on attention Proccesses sequential data and encodes. Not only works for NLP but for visual transformer, text-to-image (DALL-E)Things we need to understand: Given n words how are they processed into the encoder? What is the information being sent from encoders to decoders? How does decoders generate the output?1. Given n words how are they processed into the encoder? In an encoder there are two processes 1) self-attention and 2) feed forward neural network The Self-Attention in both encoder and decoder is the cornerstone of Transformer Transformer encodes each word to feature vectors with Self-Attention (where there are dependencies between the input words) Self-Attention at high level The animal didn’t cross the street because it was too tired Self-Attention figures out what “it” is Self-Attention creates three vectors (3 NN) Queries, Keys, Values per each word Embedding vector $x_1$ is converted to these three vecotrs Then we compute the score per each word by inner producting Queries and respective Keys vectors Then we compute the attention weights by scaling followed by softmax Then the final encoding is done by the weighted sum of the Value vectors. In python it’s just a one liner if there are $n$ words, $n^2$ operations need to be computed at once (Multi-headed attention). This is the downside of Transformers To match the output, we simply pass the attention heads(encoded vectors) through additional (learnable) linear map In summary this is what we do: Why do we need positional encoding? To add the postional information of the inputs They are added to the origional embedding.2. What is the information being sent from encoders to decoders? Transformer transfers key (K) and value (V) of the topmost encoder to the decoder The output sequence is generated in an autoregressive manner. The “Encoder-Decoder Attention” layer works just like multi-headed self-attention, except it creates its Queries matrix from the layer below it and takes the Key and Values from the encoder stack.Vision Transformer Transformer Encoder is used.DALL-E Transformer Decoder is used." }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 7: Recurrent Neural Networks", "url": "/posts/07-recurrent/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-04 10:00:00 +0900", "snippet": " Sequential Model Autoregressive Model Markov Model (first-order autoregressive model) Latent Autogressive Model Recurrent Neural Network Long Short Term Network (LSTM) Forget Gate Input Gate Update Cell Output Gate Gated Recurrent Unit (GRU)Sequential Model Sequential data: audio, video, motion the biggest challenge is that we don’t know when the data ends - we don’t know the dimension of the input data Naive sequence model.Autoregressive Model This model fixes the past timespan so that we only check $\\tau$ past data.Markov Model (first-order autoregressive model) This is the easiest representation of an autoregressive model Only dependent on the step just before Quite ridiculous as it throws away too much infomation But it’s very easy to represent.Latent Autogressive Model This model adds a hidden latent state, $h_t$, which acts as a summary of the past.Recurrent Neural Network If you spread it out with respect to time, you get the image on the right. the biggest problem is short-term dependencies the further away the past data, the weaker it is this is caused by vanishing gradient (if activation function is sigmoid) or exploding gradient (if activation function is ReLU). Long Short Term Network (LSTM) This moodel was created to solve the short-term dependency problem of RNN $x_t$ = input $h_{t-1}$ = previous hiddent state and $h_t$ = output(hidden state) $C_{t-1}$ = previous cell state and $C_t$ = next cell state.There are three gates $\\sigma$ in order: forget gate input gate output gate.Forget Gate Forget gate decides which information to throw away.Input Gate Input gate decides which information to store in the cell state.Update Cell Update the cell state.Output Gate Make output using the update cell state.Gated Recurrent Unit (GRU) It’s an altered LSTM model It’s a simpler architecture with two gates (reset gate and update gate) No cell state, just hidden state GRU has less parameters than LSTM In truth, both GRU and LSTM are not really used nowadays since they were replaced by a better performing model, Transformers.reference" }, { "title": "[boostcamp AI Tech][Day 11] Week 3 Monday", "url": "/posts/day-11/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ml basic, level 1, week 3, day in review", "date": "2022-10-03 23:00:00 +0900", "snippet": " Language is the source of misunderstandings. - Antoine de Saint-ExupéryDay in ReviewDeep Learning Basics LecturesThe lectures were uploaded to boostcourse at 9 am and I started watching them. They were fairly straight forward basic overview of different deep learning models like CNN, RNN, generative models and tranformers. It started off with a brief historical review and Multi Layer Perceptron and I just about finished watching the last lecture on Convolution Neural Network. There were 5 assignments but they were very basic follow-along-the-praticals-shown-in-the-lecture kind of assignments so they took little to no time. I did them first. I will of course have to review them, understand the code line by line so that I can later replicate them on my own.SummaryToday was the substitute holiday for Foundation Day of Korea. It was overall a good day. I was able to concentrate well and learn a lot. I especially enjoyed watching the lecture briefly reviewing 5 CNN architectures focusing on how they improved upon the preceding models. I’ve also started my journey of building good eating and sleeping habits which will hopefully help with my mood swings. Let’s make this week, yet another great week!" }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 6: Computer Vision Applications", "url": "/posts/06-computer/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-03 14:00:00 +0900", "snippet": " Going into the LectureGoing into the Lecture We explore the ways in which Computer Vision uses CNN Semantic segmentation Object detection. Semantic Segmentation Labeling pixel by pixel Also called dense classification or per-pixel classification Used in autonomous driving.Fully Convolutional Network Aim to remove the fully connected layer through convolutionalization. doesn’t actually affect the number of parameters but… transforming fully connected layers into convolution layers enables a classification net to output a heat map. While FCN can run with inputs of any size, the output dimensions are typically reduced by subsampling So we need a way to connect the coarse output to the dense pixels. i.e. upsampling, deconvolution, unpooling, convolution transpose.Deconvolution (conv transpose) technically you can’t actually get back the data by deconvolution (it’s not an inverse of convolution) but you can atleast get the size that you want.Object DetectionR-CNN R-CNN does this: Take an input image extract around 2000 region proposals using Selective Search Compute features for each proposal (using AlexNet) Classify with linear SVMs. Basically a brute force method Not perfect Slow But WorksSPPNet (Spatial Pyramid Pooling) In R-CNN, the number of crop/warp is usually over 2000 meaning that CNN must run more than 2000 times (CPU takes 59s per image) However, in SPPNet, CNN runs once on the entire imageFast R-CNN Take an input and a set of object proposals Generate a conv feature map for each bounding box, get a fixed-length feature vector from ROI pooling layer and fcs Outputs two information k+1 class labels bounding box locations Faster R-CNN Faster R-CNN = Fast R-CNN + Region Proposal NetworkRegional Proposal Network is a FCN which outputs K*(4+2) sized vectors Input an image of any size Generate conv feature map Map to a lower-dimensional feature Output objectness score and bounding boxYOLO (You Only Look Once) YOLO(v1) is an extremely fast object detection algorithm baseline: 45fps / smaller version: 155fps It simultaneously predicts multiple bounding boxes and class probabilities No explicit bounding box sampling (compared with Faster R-CNN). Given an image, YOLO divides it into S x S grid If the center of an object falls into the grid cell, that grid cell is responsible for detection Each cell predicts B bounding boxes (B = 5) Each bounding box predicts box refinement (x / y / w / h) confidence (of objectness) Each cell predicts C class probabilities In total, it becomes a tensor with S x S x (B*5 + C) size S x S: number of cells of the grid B*5: B bounding boxes with offsets(x,y,w,h) and confidence C: number of classes. " }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 5: Modern Convolutional Neural Networks", "url": "/posts/05-modern/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-03 13:00:00 +0900", "snippet": " Going into the Lecture ILSVRC AlexNet(2012) VGGNet(2014) GoogLeNet(2014) ResNet(2015) DenseNet(2017) SummaryGoing into the Lecture We have a look at five ImageNet winning CNN architectures to understand their core ideas and structures. AlexNet (2012) - first DL architecture to win ILSVRC VGG (2014) - Very deep convolutional network that uses smaller size filters (3x3) aimed to reduce the # of parameters GoogLeNet (2014) - Introduced inception blocks ResNet (2015) - Introduced residual block to reduce overfitting DenseNet(2017) - Similar in idea to ResNet but used Concatenation instead of Addition. ILSVRC ImageNet Large-Scale Visual Recognition Challenge Tests Classification / Detection / Localization / Segmentation 1000 different categories Over 1 million images Training set: 456,567 images and counting. Considering that human average performance is lower than 2015’s winning architecture’s, it is a little meaningless.AlexNet(2012) The input to the network is a batch of RGB images of size 227x227x3 and outputs a 1000x1 probability vector one correspoding to each class One of the first deep CNN to achieve considerable accuracy with an accuracy of 84.7% on the 2012 ILSVRC challenge The network consists of 5 CONV layers and 3 FC layers The activation used is ReLU (before AlexNet it was sigmoid and tanh) Preserves properties of linear models Easy to optimize with gradient descent Good generalizationo Overcome the vanishing gradient problem Although ReLU helps with the vanishing gradient problem, due to its unbounded nature, the learned variables can become unnecessarily high. To prevent this, AlexNet introduced Local Response Normalization (LRN) Used 2 GPUs Data augmentation and dropout is carried out to reduce over-fitting. (Mirroring, cropping) The network uses an overlapped max-pooling layer after the 1st, 2nd and 5th CONV layers Overlapped maxpool layers are simply maxpool layers with strides less than the window size. 3x3 maxpool layer is used with a stride of 2 hence creating overlapped receptive fields. This overlapping improved the top-1 and top-5 errors by 0.4% and 0.3%, respectively. VGGNet(2014) Why? Born out of the need to reduce the # of parameters in the CONV layers and improve on training time There are multiple variants of VGGNet (VGG16, VGG19, etc.) which differ only in the total number of layers in the network (16 layers, 19 layers, etc) All the conv kernels are of size 3x3 and maxpool kernels are of size 2x2 with a stride of two The idea behind having fixed size kernels is that all the variable size convolutional kernels used in Alexnet (11x11, 5x5, 3x3) can be replicated by making use of multiple 3x3 kernels as building blocks. The replication is in terms of the receptive field covered by the kernels 5x5 kernel can be replicated by two 3x3 kernels. As you can see having two 3x3 filter CONV layers is much better than one 5x5 filter CONV layer Similarly, the effect of one 7x7 (11x11) conv layer can be achieved by implementing three (five) 3x3 conv layers with a stride of one. This reduces the number of trainable variables by 44.9% (62.8%).GoogLeNet(2014) Won the ILSVRC at 2014 combined network-in-network (NiN) with inception blocks 22 layers 1x1 convolutions used effectively In an image classification task, the size of the salient feature can considerably vary within the image frame. Hence, deciding on a fixed kernel size is rather difficult. Lager kernels are preferred for more global features that are distributed over a large area of the image, on the other hand, smaller kernels provide good results in detecting area-specific features that are distributed across the image frame. For effective recognition of such a variable-sized feature, we need kernels of different sizes. That is what Inception does. Instead of simply going deeper in terms of the number of layers, it goes wider. Multiple kernels of different sizes are implemented within the same layer The Inception network architecture consists of several inception moduels of the following structure. Each inception modules consists of four operations in parallel 1x1 conv layer: for depth reduction (to reduce the number of parameters) 3x3 conv layer: captures distributed features 5x5 conv layer: captures global features max pooling: captures low level features that stand out in a neighborhood. all of these features are extracted and concatenated before it is fed to the next layer below shows the benefit of 1x1 convolutions.ResNet(2015) Deeper neural networks are hard to train Overfitting is usually caused by an excessive number of parameters ResNet adds an identity map/shortcut (skip connection) to solve the vanishing gradient problem exacerbated by deep networks. In the case where the channel depth doesn’t match, ResNet uses projected shortcut that uses 1x1 conv to match the channel depth. interestingly batch norm is done after 3x3 convolution bottleneck architecture uses 1x1 conv to reduce input channel and then increase it back to match whatever channel we want. Performance increase while paramter size decreases.DenseNet(2017) DenseNet usese conactenation instead of addition This means that the data doesn’t mix. Dense Block Each layer concatenates the feature maps of all preceding layers The number of channels increases geometrically Transition Block BatchNorm -&gt; 1x1 conv -&gt; 2x2 AvgPooling This reduces the number of channels that were increased by Dense Blocks. Summary Key Takeaways AlexNet: ReLu, Data augmentation VGG: repeated 3x3 blocks GoogLeNet: 1x1 convolution and inception modules ResNet: skip connection DenseNet: concatenation. reference" }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 4: Convolutional Neural Networks", "url": "/posts/04-convolutional/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-03 12:00:00 +0900", "snippet": " Convolution Neural Networks Stride Padding 1x1 ConvolutionConvolution Neural Networks Depending on the filter, 2D convolution will have different effects (Blur, Emoss, Outline, etc). If you want the output to have n channels, you also need to have n filters To calcualte the number of parameters in the output layer after a convolution layer (given padding(1) and stride(1), 3 x 3 kernel): $\\text{# of parameters} = \\text{kernel size} \\times \\text{# of input channel} \\times \\text{# of output channel}$. CNN consists of convolution layer, pooling layer, and fully connected layer Convolution and pooling layers: feature extraction pooling layers are used to reduce the dimensions of the feature maps. Thus it reduces the number of parameters to learn and the amount of computation performed in the network. Fully connectedlayer: decision making (e.g. classification) However we tend to not use FC layers anymore as it increases the number of parameters too much so learning becomes difficult and the generalization performance decreases Stride Stride measures by how many pixels the filter will move So it measures how densely you will use the filter on the imagePadding Padding refers to the amount of pixels added to an image to its fringe when it is being processed by the kerenl of a CNN Zero padding and and stride = 1 results in the output having the same dimension as the input To calculate the size of the output volume, given input volume size $W$, kernel field size $K$, $padding(P)$ and $stride(S)$ use the formul below.\\[\\text{Spatial Size of the Output Volume} = \\frac{W - K + 2P}{S} + 1\\]1x1 Convolution Pixel by pixel operation It’s used for channel-wise dimension reduction It’s used to reduce the number of parameters while increasing the depth e.g. bottleneck architecture." }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 3: Optimization", "url": "/posts/03-optimization/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-03 11:00:00 +0900", "snippet": " Going into the Lecture Important Concepts in Optimization Generalization(일반화) Underfitting vs. Overfitting Cross-Validation Bias and Variance Bootstrapping Bagging vs. Boosting Gradient Descent Methods Batch-size Matters Gradient Descent Methods Gradient Descent Momentum Nesterov Accelerated Gradient(NAG) Adagrad Adadelta RMSprop Adaptive Moment Estimation(Adam) Regularization Early Stopping Parameter Norm Penalty Data Augmentation Noise Robustness Label Smoothing Dropout Batch Normalization Going into the Lecture Gradient Descent This is the 1st order iterative optimization algorithm for finding a local minimum of a differentiable function. Important Concepts in Optimization Generalization Under-fitting vs. Over-fitting Cross Validation Bias-Variance Tradeoff Bootstrapping Bagging and BoostingGeneralization(일반화) Generalization refers to how well the learned model is behaving on unseen (test) data If the test error is close to training error, then the model has good generalization.Underfitting vs. Overfitting The model is underfitting the training data when the model performs poorply on the training data The model is overfitting the training data if the model performs well on the training data but does not perform well on the test data This is because the model is memorizing the data it has seen and is unable to generalize to unseen samples So this is an example of bad generalization. Cross-Validation Cross-Validation is a model validation technique for assessing how the model will generalize to an independent (test) data set. It is also called K-Fold Validation.Bias and Variance Variance: How close are the outputs given similar inputs? Low Variance = outputs are close together Bias: How close is the output to the target? Low Bias = outputs are close to targetBootstrapping Bootstrapping is any test or metric that uses random sampling with replacement And then we check the consensus of the models to test uncertaintyBagging vs. Boosting Bagging is short for Bootstrapping aggregating Multiple models are trained with bootstrapping ex) Base classifiers are fitted on random subset where indivdual predictions are aggregated (voting or averaging) Often use Ensemble technique Boosting It focuses on those specific training samples that are hard to classify A strong model is built by combining weak learners in sequence where each leaerner learns from the mistakes of the previous weak learnerGradient Descent Methods Stochastic Gradient Descent (SGD) Update with the gradient computed from a single sample Mini-batch Gradient Descent Update with the gradient computed from a subset of data Batch Gradient Descent Update with the gradient computed from the whole data. Batch-size Matters Large batch methods tend to converge to sharp minimizers of the training and testing functions Small batch methods consistently converge to flat minimizers This is due to the inherent noise in the gradient estimation Generalization Performace improves with smaller batch methods.Gradient Descent Methods Stochastic Gradient Descent Momentum Nesterov Accelerated Gradient Adagrad Adadelta RMSprop Adam.Gradient Descent\\[W_{t+1} \\leftarrow W_{t} - \\eta g_{t}\\] where $W = weight$, $g_t = gradient$ and $\\eta = learning \\space rate$ It’s important to choose the appropriate learning rate. Momentum\\[\\begin{aligned} &amp; a_{t+1} \\leftarrow \\beta a_{t} + g_{t} \\\\ &amp; W_{t+1} \\leftarrow W_{t} - \\eta a_{t+1}\\end{aligned}\\]where $a_{t+1} = accumulation$ and $\\beta = momentum$ $\\beta a_{t}$ acts as a stabilizer pushing the accumulation to one direction helps to overcome oscillationNesterov Accelerated Gradient(NAG) NAG is a slightly modified version of Momentum with stronger theoretical convergence guarantees for convex functions In practice, it has produced slightly better results than classical Momentum Further Reading\\[\\begin{aligned} a_{t+1} &amp;\\leftarrow \\beta a_{t} + \\nabla\\mathcal{L}(W_{t} - \\eta\\beta a_{t}) \\\\ W_{t+1} &amp;\\leftarrow W_{t} - \\eta a_{t+1}\\end{aligned}\\] $\\nabla\\mathcal{L}(W_{t} - \\eta\\beta a_{t})$ is the lookahead gradient and it tries to prevent overshoot.Adagrad\\[\\begin{aligned} W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}} g_{t}\\end{aligned}\\]where $G_{t}$ = Sum of gradient squares and $\\epsilon$ is for numerical stability. Adagrad adapts the learning rate, performing larger updates for infrequent parameters and smaller updates for frequent parameters Ada is short for adaptive learning rate approach If training occurs for a long period, $\\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}}$ converges to 0 resulting in no learningAdadelta Adadelta extends Adagrad to reduce its monotonically decreasing the learning rate by restricting the accumulation window.\\[\\begin{aligned} G_t &amp;= \\gamma G_{t-1} + (1-\\gamma)g_{t}^2 \\\\ W_{t+1} &amp;= W_{t} - \\frac{\\sqrt{H_{t-1} + \\epsilon}}{\\sqrt{G_{t}+\\epsilon}}g_t \\\\ H_t &amp;= \\gamma H_{t-1} + (1-\\gamma)(\\Delta W_t)^2\\end{aligned}\\]where $G_t$ = EMA of gradient squares and $H_t$ = EMA of difference squares (EMA = Exponential Moving Average) There is no learning rate in Adadelta We don’t really use this a lotRMSprop RMSprop is an unpublished, adaptive learning rate method proposed by Geoff Hinton in his lecture.\\[\\begin{aligned} G_t &amp;= \\gamma G_{t-1} + (1-\\gamma)g_{t}^2 \\\\ W_{t+1} &amp;= W_{t} - \\frac{\\eta}{\\sqrt{G_{t}+\\epsilon}}g_t\\end{aligned}\\]where $\\eta$ = stepsize RMSprop adds stepsize to AdadeltaAdaptive Moment Estimation(Adam) Adam leverges both past gradients and squared gradients. So combined the ideas in momentum and adaptive learning rate approach.\\[\\begin{aligned} m_t &amp;= \\beta_1 m_{t=1} + (1-\\beta_1)g_t \\\\ v_t &amp;= \\beta_@ v_{t-1} + (1-\\beta_2)g_t^2 \\\\ W_{t+1} &amp;= W_t - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}}\\frac{\\sqrt{1-\\beta_2^t}}{1-\\beta_1^t}m_t\\end{aligned}\\]where $m_t$ = momentum, $v_t$ = EMA of gradient squares and $\\frac{\\sqrt{1-\\beta_2^t}}{1-\\beta_1^t}$ = unbiased estimator. Best to use.Regularization Tools used to make better generalizations Early stopping Parameter norm penalty Data augmentation Noise robustness Label smoothing Dropout Batch normalization Early Stopping Stop iteration early when the generalization gap increases.Parameter Norm Penalty It adds smoothness to the function space.\\[\\text{total cost} = \\text{loss}(\\mathcal{D}; W) + \\frac{\\alpha}{2}||W||_2^2\\] also called weight decay prevents parameter from exploding by also minimizing the Parameter Norm Penalty, $\\frac{\\alpha}{2}   W   _2^2$. Data Augmentation More data the better Artificially increase the number of data by undergoing label preserving augmentations (strech, rotate, etc).Noise Robustness Add random noise to inputs or weights It somehow works better.Label Smoothing Mix-up constructs augmented training examples by mixing both input and output of two randomly selected training data CutMix constructs augmented training exmaples by mixing inputs with cut and paste and outputs with soft labels of two randomly selected training data CutOut crop a certain section of training examples.Dropout In each forward pass, randomly set some neurons to zero.’ It’s like training multiple models.Batch Normalization Batch normalization compute the empirical mean and variance independently for each dimension (layers) and normalize.\\[\\begin{aligned} \\mu_{B} &amp;= \\frac{1}{m}\\sum_{i=1}^m x_i \\\\ \\sigma^2_{B} &amp;= \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{B})^2 \\\\ \\hat{x}_i &amp;= \\frac{x_i - \\mu_{B}}{\\sqrt{\\sigma^2_{B}+\\epsilon}}\\end{aligned}\\] There are other norms like Layer Norm, Instance Norm and Group Norm." }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 2: Neural Networks & Multi-Layer Perceptron", "url": "/posts/02-neural-networks/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-03 10:00:00 +0900", "snippet": " Going into the Lecture Linear Neural Networks Multi-layer Perceptron Activation FunctionsGoing into the Lecture Neural Networks are function approximators that stack affine transformations followed by nonlinear transformations. (수학적인 정의)Linear Neural Networks 목표: n개의 데이터를 잘 설명하는 모델을 찾는 것 그래서 데이터와 모델의 차이를 줄이는 것이 중요 그래서 MSE를 사용한다 Gradient Descent를 할 때 learning rate를 잘 정해줘야한다.Multi-layer Perceptron To use multi-dimensional input and output, we use vectors and matrices One way to interpret a matrix is to regard it as a mapping between two vector spaces.Activation Functions we add activation functions to act as non-linear tranformations." }, { "title": "[boostcamp AI Tech][DL Basic] Lecture 1: Historical Review", "url": "/posts/01-historical-review/", "categories": "boostcamp AI Tech, Week 3 - DL Basic", "tags": "boostcamp, dl basic, level 1, week 3", "date": "2022-10-03 09:00:00 +0900", "snippet": " Going into the LectureGoing into the Lecture Key components of Deep Learning The data the model can learn from The model to transform the data The loss function to quantify the badness of the model The algorithm to adjust the parameters to minimize the loss Whenever looking at research papers, have these four components in mind to see in which aspect the paper is contributing.1. Data Data depend on the type of the problem we are trying to solve Classification: classify the image Semantic Segmentation: partition the image to different objects by pixel Detection: Find bounding boxes of objects in images Pose estimation: Find 3D or 2D skeleton information Visual QnA: Answer a question concerning the image in question. 2. Model AlexNet, GoogLeNet, LSTM, Deep AutoEncoders, GAN 등 다양한 모델들이 있다3. Loss The loss function is a proxy of what we want to achieve. (Not exactly what we want) Regression Task: Mean Square Error(MSE) Classification Task: Cross Entropy(CE) Probabilitistic Task: Maximum Likelihood Estimator(MLE)4. Optimization Algorithm SGD, Momentum, NAG, Adagrad, Adadelta, RMSprop Regularizations: Dropout, Early Stopping, K-fold Validation, Weight Decay, Batch Normalization, MixUp, Ensemble, Bayesian OptimizationHistorical Review Follows Denny Britz article (source)2012 - AlexNet 224 x 224 이미지를 분류하는 대회 ILSVRC에서 최초로 DL 모델로 1등을 했고 DL의 시대가 열리게 되었다.2013 - DQN (Deep Q-Network) 알파고 vs 이세돌의 시작이 DQN이다 딥마인드의 연구결과 Atari 2600에서 블록깨기 게임을 강화학습을 이용해 풀어내려고 만든 모델 Q-Learning이라는 방식을 DL과 접목시켜서 학습했다.2014 - Encoder / Decoder 단어의 연속이 주어졌을 때 다른 언어의 단어의 연속으로 출력하는데 사용한다 Sequence-to-Sequence(Seq-2-Seq)를 할 수 있게 되었다.2014 - Adam Optimizer 그냥 잘 작동한다.2015 - Generative Adversarial Network(GAN) Network가 스스로 학습 데이터(generator, discriminator)를 만들어내서 학습을 한다 중요하다.2015 - Residual Networks(ResNet) 예전에 딥러닝은 layer가 너무 많으면 성능이 떨어졌었다 Network를 깊게 쌓아도 문제가 발생하지 않게 했다.2017 - Transformer Attention Is All You Need이라는 논문으로 발표를 했다 Transfer가 기존의 RNN의 분야에서 RNN을 다 대체를 하고 vision까지 넘보고 있다 매우 중요하다 어떤 장점이 있고 왜 좋은 성능을 내는지 알아야한다.2018 - BERT(fine-tuned NLP models) Bidirectional Encoder Representations from Transformers 학습 데이터(news)가 많지 않을 때 큰 규모의 corpus(wikipedia)를 사용해서 pre-training,2019 - Big Language Models: GPT-X BERT의 끝판왕 parameter가 굉장히 많아서 붙어진 이름이다 (billion 단위).2020 - Self Supervised Learning unlabeled data를 사용해서 학습을 한다 supervised랑 unsupervised의 중간이라고 할 수 있다 스스로 label을 만든다 audio processing, speech recognition에서 좋은 성능을 보이고 있다." }, { "title": "[boostcamp AI Tech][Day 10] It's Already Friday Again", "url": "/posts/day-10/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, pytorch, level 1, week 2, day in review", "date": "2022-09-30 21:00:00 +0900", "snippet": " Not a shred of evidence exists in favor of the idea that life is serious. - Henry Brendan GillDay in ReviewFirst “Special” Peer SessionToday, we had our special peer session for the first time. Each student was assigned to a random zoom meeting room so that we could talk to people besides our teammates. It was interesting to talk to other people and see how they are doing. Variety is always good, I guess.Master Session: Data-centric AIThe boostcamp director gave us a lecture on data-centric AI and also gave general career advice. Basically, models have been perfected over the decade and the big difference you can make in your model is now having good data. And he told us that there are key things that ML engineers need to know: MLOps database Cloud - AWS, GCP, Azure Spark (+ Hadoop) Linux + Docker and maybe Kubernetes and KubeFlow, MLFlow, AirflowThat’s a whole lot to learn besides following the boostcamp programme.PyTorch LecturesI finished watching this week’s lectures. The last three that I watched today were on Multi-GPU, hyperparameter tuning, and troubleshooting. They were easy to follow along but I am sure when it comes to implementation, I will have difficulty.SummaryI am really enjoying learning but there is just so much. It will be very important to manage the load very well. In the end, I just have to study efficiently and study longer hours. I just have to take it one by one. Just, just, just… Only if everything was simple as saying the word “just”. Regardless, I press on." }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 10: PyTorch Troubleshooting", "url": "/posts/10-pytorch-troubleshooting/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-30 13:00:00 +0900", "snippet": " Going into the LectureOut of Memory(OOM)이 해결하기 어려운 이유들 왜 발생했는지 알기 어렵다 어디서 발생했는지 알기 어렵다 Error backtracking이 이상한데로 간다 (GPU는 거짓말을 한다) 메모리의 이전 상황을 파악이 어렵다. 1차원적 해결방법: batch size를 줄이고 GPU를 clean (colab에서는 relaunch) 다시 run.GPUUtil 사용하기 nvidia-smi 처럼 GPU의 상태를 보여주는 모듈이다 Colab은 환경에서 GPU 상태를 보여주기가 편하다 iteration 마다 메모리가 늘어나는지 확인이 가능하다 !pip install GPUtil import GPUtil GPUtil.showUtilizationtorch.cuda.empty_cache() 써보기 사용되지 않은 GPU상 cache를 정리하여 가용 메모리를 확보한다 del과는 구분이 필요하다 (del은 관계만 끊는다) reset 대신 쓰기 좋은 함수이다.# del vs torch.cuda.empty_cache()import torchfrom GPUtil import showUtilization as gpu_usageprint(\"Initial GPU Usage\")gpu_usage()tesnorList = []for x in range(10): tensorList.append(torch.randn(10000000,10),cuda())print(\"GPU Usage after allocating a bunch of Tensors\")gpu_usage()del tensorListprint(\"GPU Usage after deleting the Tensors\")gpu_usage()print(\"GPU Usage after emptying the cache\")torch.cuda.empty_cache()gpu_usage()training loop에 tensor로 축적 되는 변수는 확인할 것 tensor로 처리된 변수는 GPU 상에 메모리를 사용한다 해당 변수가 loop안에 연산이 있을 때 GPU에 computational graph를 생성한다(메모리 잠식).# don't dototal_loss = 0for i in range(10000): optimizer.zero_grad() output = model(input) loss = criterion(output) loss.backward() optimizer.step() total_loss += loss # 이럴 경우에는 loss_1 + loss_2 + loss_3... 로 저장이 된다 1-d tensor의 경우에는 python 기본 객체로 변화하여 처리를 해야한다.# dototal = loss = 0for x in range(10): #assume loss is computed iter_loss = torch.randn(3, 4).mean() iter.loss.requires_grad = True total_loss += iter_loss.itemdel 명령어를 적절히 사용하기 필요가 없어진 변수는 적절한 삭제가 필요하다 python의 메모리 배치 특성상 loop이 끝나도 메모리를 차지한다.for x in range(10): i = xprint(i) # 9 is printed가능 batch 사이즈를 실험해보기 학습시 OOM이 발생했다면 batch 사이즈를 1로 해서 시험해보기oom = Falsetry: run_model(batch_size)except RuntimeError: # Out of Memory oom = Trueif oom: for _ in range(batch_size): run_model(1)torch.no_grad() 사용하기 Inference 시점에서는 touch.no_grad() 구문을 사용하기 bachward pass으로 인해 쌍이는 메모리에서 자유로워진다.with torch.no_grad() for data, target in test_loader: output = network(data) test_loss += F.nll_loss(....) ...예상치 못한 에러 메세지 OOM 말고도 유사한 에러들이 발생한다 CUDNN_STATUS_NOT_INIT이나 device-side-assert등이 있다 해당 에러도 cuda와 관련하여 OOM의 일종으로 생각될 수 있으며, 적절한 코드 처리가 필요하다.그 외 colab에서 너무 큰 사이즈는 실행하지 말 것 (linear, CNN, LSTM) CNN의 대부분의 에러는 크기가 안 맞아서 생기는 경우 (touchsummary등으로 사이즈를 맞출 것) tensor의 float precision을 16bit로 줄일 수도 있다 결국엔 구글링이 답이다.Further Reading GPU 에러 정리 OOM시에 GPU 메모리 flush하기 PyTorch에서 자주 발생하는 에러 질문들" }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 9: Hyperparameter Tuning", "url": "/posts/09-hyperparameter-tuning/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-30 12:00:00 +0900", "snippet": " Going into the Lecture Hyperparameter Tuning Grid vs Random Layout RayGoing into the Lecture 모델 성능을 좋게 만드는 법은 크게 3가지가 있다 모델 바꾸기: 이미 고정된 좋은 모델을 사용한다 (RESNET, CNN, Transformer) 데이터 바꾸기: 가장 좋은 방법이다 hyperparameter tuning. Hyperparameter Tuning 모델 스스로 학습하지 않는 값을 우리가 지정해야 한다. (Learning rate, 모델의 크기, optimizer 등등) 한때는 하이퍼 파라메터에 의해서 값이 크게 좌우 될 때가 있었지만 요즘은 극도로 많은 데이터로 완화를 했다 당연히 하지만 중요도가 좀 낮아졌다. (옛날에는 ‘손맛’이라고…)Grid vs Random Layout 기본적으로 grid, random search가 있는데 최근에는 베이지안 기반 기법들을 많이 사용한다 grid layout 때는 log를 취해서 값을 올려준다.Ray multi-node multi processing 지원 모듈 ML/DL의 병렬 처리를 위해 개발된 모듈 기본적으롤 현재의 분산병렬 ML/DL 모듈의 표준 Hyperparameter Search를 위한 다양한 모듈을 제공한다.from ray import tunefrom ray.tune import CLIReporterfrom ray.tune.schedulers import ASHASchedulerdata_dir = os.path.abspath(\"./data\")load_data(data_dir)config = { \"l1\": tune.sample_from(lambda: 2**np.random.randint(2,9)), \"l2\": tune.sample_from(lambda: 2**np.random.randint(2,9)), \"lr\":tune.loguniform(1e-4, 1e-1), \"batch_size\": tune.choice([2,4,8,16]) # config search space 지정}scheduler = ASHASceduler(metric=metric, mode=mode, max_t=max_num_epochs, grace_period=1, reduction_factor=2) # 학습 스케줄링 알고리즘 지정reporter = CLIReporter(metric_colums=[\"loss\", \"accuracy\", \"training_iteration\"]) # 결과 출력 양식result = tune.run( partial(train_cifar, data_dir=data_dir), resource_per_trial={'cpu':2, 'gpu':gpus_per_tiral}, config=config, num_samples=num_samples, scheduler=scheduler, progress_reporter=reporter) # 병렬 처리 양식으로 학습 시행" }, { "title": "[boostcamp AI Tech][Day 9] Done with Assignments", "url": "/posts/day-9/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, pytorch, level 1, week 2, day in review", "date": "2022-09-29 22:00:00 +0900", "snippet": " Men are born to succeed, not fail. - Henry David ThoreauDay in ReviewTA Session: Assignments ReviewThese are 1 hour assignment review sessions and given that the assignments were very long, there is a limit to how detailed the TAs can go through them. Regardless, it was really helpful to see their code and thought process.MiscellaneousNone.Things I Will DoTomorrow Exercise and clean my room in the morning 1 hour of algorithm study Finish Assignment 2 Sleep before 1 am.Down the Line Learn Regular Expression Learn what an API is Learn about Git (Crash Course on Youtube) Read this Study the book, “Mathematics for Machine Learning” (this is the book) Learn about the tools in Github Student Pack Learn about DevOps Find which company I would want to work for.SummaryI need to make sure that I have time to write these posts. Basically, I need to plan my day better. Keeping a blog takes a lot of effort." }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 8: Multi-GPU 학습", "url": "/posts/08-multi-gpu/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-29 12:00:00 +0900", "snippet": " Going into the Lecture 개념 정리 Model Parallelism Data ParallelismGoing into the Lecture 예전에는 어떻게 GPU를 덜 사용할까 고민을 했다면 이제는 얼마나 GPU를 많이 + 잘 사용해서 큰 모델을 학습 시킬까가 초점이다 오늘날은 딥러닝은 엄청난 데이터와의 싸움을 하고 있다개념 정리 Single GPU는 GPU 1개를 때, multi GPU는 GPU를 두 개 이상사용할 때를 말한다 우리가 Node(System)를 사용한다고 할때는 1대의 컴퓨터를 뜻한다 Single Node single GPU: 평소 데스크탑 컴퓨터 Single Node Multi GPU: 컴퓨터에 GPU가 여러 장 들어있을 때 Multi Node Multi GPU: 대용량 서버에서 하듯이 여러 컴퓨터에 여러 GPU NVIDIA에서 이런 Multi GPU를 지원해주기 위해 TensorRT 8.0라는 도구를 공개했다.Model Parallelism 다중 GPU에 학습을 분산하는 2가지 방법이 있다 모델 병렬화: Alexnet 부터 사용했었음. 하지만 병목, 파이프라인의 어려움 등으로 인해 모델 병렬을 어려운 과제이다. 그렇게 흔하지는 않다 데이터 병렬화 Data Parallelism 데이터를 나눠 GPU에 할당한 후 결과의 평균을 취하는 방법이다 minibatch 수식과 유사한데 한번에 여러 GPU에서 수행한다 PyTorch에서 2가지 Data Parallel 방식을 제공한다 DataParallel 데이터를 GPU들로 분배한 후 평균을 취한다 GPU 사용 뷸균형 문제 발생, batch 사이즈 감소(main GPU가 병목) coodinating 하는 main GPU가 메모리가 부족하다 Global Iterpreter Lock 문제가 생긴다 # DataParallelparallel_model = torch.nn.DataParallel(model) # Encapsulate the model (이게 전부)predictions = parallel_model(inputs) # Forward pass on multi-GPUsloss = loss_function(predictions, labels) # Compute loss fnloss.mean().backward() # Average GPU-losses + backward passoptimizer.step() # Optimizer steppredictions = parallel_model(inputs) # Forward pass with new parameters DistributedDataParallel DataParallel의 단점을 해결하려고 한다 각 CPU마다 process를 생성하여 개별 GPU에 할당 즉 모으는 작업이 없고 각각 연산을 진행하고 결과만을 합쳐 평균은 낸다. 다시 말해 기본적으로 DataParallel로 하지만 개별적으로 연산의 평균을 낸다. sampler = torch.utils.data.distributed.DistributedSampler(train_data)shuffle = Falsepin_memory = Truetrain_loader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=shuffle, pin_memory=pin_memory, num_workers=3,sampler=sampler) # num_workers = GPU x 4def main(): n_gpu = torch.cuda.device_count() torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, ))def main_worker(gpu, n_gpus): image_size = 224 batch_size = 512 num_worker = 8 epoch = ... batch_size = int(batch_size/n_gpus) num_worker = int(num_worker/n_gpus) # set multiprocessing protocol model = MODEL torch.cuda.set_device(gpu) model = model.cuda(gpu) model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu]) # Distributed DataParallel 정의from multiprocessing import Pooldef f(x): # python의 멀티프로세싱 코드 return # your functionif __name__ == '__main__': with Pool(4) as p: print(p.map(f, [1,2,3]))" }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 7: Monitoring Tools for PyTorch", "url": "/posts/07-monitoring/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-29 12:00:00 +0900", "snippet": " Going into the Lecture Tensorboard weight &amp; biasesGoing into the Lecture 학습 시간이 길기 때문에 기다림의 기록이 필요한데 좋은 도구들이 많다 Tensorboard와 weight &amp; biases라는 도구가 있다Tensorboard TensorFlow의 프로젝트로 만들어진 시각화 도구이다 학습 그래프, metric, 학습 결과의 시각화를 지원한다 PyTorch도 연결이 가능하며 DL 시각화하는데 핵심 도구이다 scalar: metric등 상수 값의 연속(epoch)을 표시 graph: 모델의 computational graph 표스 histogram: weight등 값의 분포를 표현 image: 예측 값과 실제 값을 비교해서 표시 mesh: 3D 형태의 데이터를 표현하는 도구import oslogs_base_dir = \"logs\"os.makedirs(logs_base_dir, exist_ok = True) # Tensorboard 기록을 위한 directory 생성from torch.utils.tensorboard import SummaryWriter # 기록 생성 객체 SummaryWriter 생성import numpy as npwriter = SummaryWriter(logs_base_dir) # 어디에 기록해야 되는지 설정for n_iter in range(100): writer.add_scalar('Loss/train', np.random.random(), n_iter) # add_scalar: scalar 값을 기록 writer.add_scalar('Loss/test', np.random.random(), n_iter) # Loss/train: loss category에 train 값 writer.add_scalar('Accuracy/train', np.random.random(), n_iter) # n_iter: x 축의 값 writer.add_scalar('Accuracy/test', np.random.random(), n_iter)writer.flush() # 값을 disk에 쓰기(기록하기)%load_ext tensorboard #jupter 상에서 tensorboard 수행%tensorboard --logdir{logs_base_dir} # 파일 위치 지정. 같은 명령어를 콘솔에서도 사용 가능하다weight &amp; biases 머신러닝 실험을 원활히 지원하기 위한 상용도구이다 협업, code versioning, 실험 결과 기록 등을 제공한다 MLOps의 대표적인 툴로 저변 확대 중이다.!pip instal wandb -q import wandbwandb.init(project=\"my_project_name\", entity=\"user_name\") #wandb 연결EPOCHS = 100BATCH_SIZE = 64LEARNING_RATE = 0.001config={\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE, \"learning_rate\" : LEARNING_RATE}wandb.init(project=\"my_project_name\", config=config)# wandb.config.batch_size = BATCH_SIZE# wandb.config.learning_rate = LEARNING_RATE# config={\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE, \"learning_rate\" : LEARNING_RATE}for e in range(1, EPOCHS+1): ''' your train valid code ''' train_loss = epoch_loss/len(train_dataset) train_acc = epoch_acc/len(train_dataset) print(f'Epoch {e+0:03}: | Loss: {train_loss:.5f} | Acc: {train_acc:.3f}') wandb.log({'accuracy': train_acc, 'loss': train_loss}) 자신의 훈련을 위한 모델의 parameter를 config로 설정해서 전달해준다 해당 모델의 훈련값이 wandb.log 코드를 통해 wandb에 전달되어 기록된다." }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 6: 모델 불러오기", "url": "/posts/06-model-copy/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-29 11:00:00 +0900", "snippet": " Going into the Lecture model.save() - 말 그대로 모델 상태를 저장하기 Kaggle Cats and Dogs Dataset으로 실습 Checkpoints Transfer Learning FreezingGoing into the Lecture backbone model이란 학습이 되어있는 모델을 가지고 와서 우리 데이터에 맞춰가지고 한번 더 학습을 시킬 때 모델을 불러와야 한다 (finetuning). model.save() - 말 그대로 모델 상태를 저장하기 학습의 결과를 저장하기 위한 함수 모델 형태(architecture)와 parameter를 저장 모델 학습 중간 과정의 저장을 통해 최선의 결과모델을 선택 만들어진 모델을 외부 연구자와 공유하여 학습 재연성 향상# 모델의 파라메터를 저장torch.save(model.state_dict(), os.path.join(MODEL_PATH, \"model.pt))# 같은 모델의 형태에서 파라메터만 loadnew_model = TheModelClass()new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH, 'model.pt')))# 모델의 architecture와 함께 저장하고 load (python pickle 방식으로 저장이 된다)torch.save(model, os.path.join(MODEL_PATH, \"model.pt\"))model = torch.load(os.path.join(MODEL_PATH, \"model.pt\"))Kaggle Cats and Dogs Dataset으로 실습 .state_dict()로 parameter를 볼 수 있지만 다른 방법도 있음:from torchsummary import summarysummary(model, ())Checkpoints 학습의 중간 결과를 저장하여 최선의 결과를 선택 earlystopping 기법 사용시 이전 학습의 결과물을 저장 loss와 metric 값을 지속적으로 확인 저장 일반적으로 epoch, loss, metric을 함께 저장하여 확인 colab에서 지속적인 학습을 위해서도 반드시 필요하다.torch.save({ 'epoch': e, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': epoch_loss, }, f\"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt\")Transfer Learning 다른 데이터셋으로 만든 pre-trained 모델을 현재 데이터에 적용한다 일반적으로 대용량 데이터세으로 만들어진 모델의 성능이 매우 좋다 현재의 DL에서는 가장 일반적인 학습 기법이다 backbone architecture가 잘 학습된 모델에서 일부분만 변경하여 학습을 수행한다 TorchVision, HuggingFace에 모델들이 있다.Freezing pretrained model을 활용시 모델의 일부분을 frezze 디버깅 때 사용한다." }, { "title": "[boostcamp AI Tech][Day 8] Busy with Assignment Day 2", "url": "/posts/day-8/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, pytorch, level 1, week 2, day in review", "date": "2022-09-28 22:00:00 +0900", "snippet": " Men are born to succeed, not fail. - Henry David Thoreau Day in Review Busy with Assignment - Day 2 Miscellaneous Things I Will Do Tomorrow Down the Line SummaryDay in ReviewBusy with Assignment - Day 2Just focusing all my attention on the assignments. I finished the first one and started the second. It is on loading the dataset and processing it before it is implemented into the model.MiscellaneousNone.Things I Will DoTomorrow Exercise and clean my room in the morning 1 hour of algorithm study Finish Assignment 2 Sleep before 1 am.Down the Line Learn Regular Expression Learn what an API is Learn about Git (Crash Course on Youtube) Read this Study the book, “Mathematics for Machine Learning” (this is the book) Learn about the tools in Github Student Pack Learn about DevOps Find which company I would want to work for.SummaryI’m learning a lot from the assignments." }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 5: PyTorch Dataset", "url": "/posts/05-pytorch-dataset/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-28 11:00:00 +0900", "snippet": " Going into the Lecture 모델에 데이터를 먹이는 방법 Dataset 클래스 Dataset 클래스 생성시 유의점 DataLoader 클래스 CasestudyGoing into the Lecture 요즘에 대용량 데이터를 어떻게 잘 넣어주는 것이 더 중요해졌다 이걸 해주는 것이 PyTorch Dataset API 이번 강의에 어떻게 기존 파일 형태에서 -&gt; 데이터 feeding 해주는지 설명한다.모델에 데이터를 먹이는 방법 Dataset Class의 getitem 하나의 데이터를 가져올 때 어떻게 데이터를 반활할지 선언해준다 transforms에서 tensor로 데이터 변환 dataloader는 data를 묶어서 (섞어주거나) 모델에 feeding.Dataset 클래스 데이터 입력 형태를 정의하는 클래스 데이터를 입력하는 방식의 표준화 Image, Text, Audio 등에 따른 다른 입력정의.import torchfrom torch.utils.data import Datasetclass CustomDataset(Dataset):\tdef __init__(self, text, labels): self.labels = labels\t\tself.data = text\t\tdef __len__(self):\t\treturn len(self.labels)\t\tdef __getitem__(self, idx):\t\tlabel = self.labels[idx]\t\ttext = self.data[idx]\t\tsample = {\"Text\": text, \"Class\": label}\t\treturn sampleDataset 클래스 생성시 유의점 data 형태에 따라 각 함수를 다르게 정의함 모든 것을 데이터 생성 시점에 처리할 필요는 없음 image의 tensor 변화는 학습에 필요한 시점에 변활 데이터 셋에 대한 표준화된 처리방법 제공 필요 후속 연구자 또는 동료에게는 빛과 같은 존재 최근에 HuggingFace등 표준화된 라이브러리 사용.DataLoader 클래스 Data의 Batch를 생성해주는 클래스 (묶어준다) 학습직전(GPU feed전) 데이터의 변환을 책임 Tensor로 변환 + Batch 처리가 메인 업무 병렬적인 데이터 전처리 코드의 고민 필요 link to pytorch doc.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, workers_init_fn=None, *, prefetch_factor=2 persistent_workers=False)Casestudy 데이터 다운로드부터 loader까지 직접 구현해보기 NotMNIST 데이터의 다운로드 자동화 도전." }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 4: AutoGrad & Optimizer", "url": "/posts/04-autograd-optimizer/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-28 10:00:00 +0900", "snippet": " torch.nn.Module nn.Parameter (class) Backward optimizer.step optimizer.zero_grad()torch.nn.Module 딥러닝을 구성하는 Layer의 base class input, output, Forward 정의 Backward는 AutoGrad으로 자동화되어 있음 학습의 대상이 되는 parameter(tensor) 정의nn.Parameter (class) Tensor 객체의 상속 객체 nn.Module 내에 attribute가 될 때는 require_grad=True로 지정되어 학습 대상이 되는 Tensor 우리가 직접 지정할 일은 잘 없음 대부분의 layer에는 weights 값들이 지정되어 있음 Backward Layer에 있는 Parameter들의 미분을 수행 Forward의 결과값 (model의 output=예측치)과 실제값간의 차이(loss)에 대해 미분을 수행 해당 값으로 Parameter 업데이트optimizer.step backward를 통해 업데이트된 parameter값으로 gradient descent 진행optimizer.zero_grad() clear gradient buffers because we don’t want any gradient from previous epoch to carry forward" }, { "title": "[boostcamp AI Tech][Day 7] Busy with Assignment", "url": "/posts/day-7/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, pytorch, level 1, week 2, day in review", "date": "2022-09-27 22:00:00 +0900", "snippet": " Men are born to succeed, not fail. - Henry David Thoreau Day in Review Busy with Assignment Concerning PyTorch Mentor Session 수학에 대해서 과제 리뷰 등의 코드 리뷰 linter 무엇을 사용하시나요? 이전 부스트캠프 기수 진로가 어떤지? 다른 분야로 이동 가능성? 성장하기 위해서 알면 좋은 것 part 1 Miscellaneous Things I Will Do Tomorrow Down the Line Summary There is not much to talk about today. I was just extremely busy with the assignment. Day in ReviewBusy with AssignmentI started the PyTorch assignment. It’s super long but that’s good because longer the exposure to PyTorch, the more acustomed I will be to the framework.Concerning PyTorch It has a BSD license so it’s free to use. Get used to PyTorch Documentation Think of dim as “collapsing” torch.gather(input, dim, index) to ‘gather’ to get diagonal of 2-D and 3-D tensorsMentor Session수학에 대해서 억지로 너무 안되는 건 붙잡지말자 모델, 자원 구축, 코딩, 서빙까지 하는게 목표 수학은 생각보다 필요가 없다 아직 NLP쪽이 한국에서 부족하다과제 리뷰 등의 코드 리뷰 Pull request(PR)을 올리는 형태가 어려우면, 피어세션에 같이 모여서 보는것도 방법 이상한 변수명, 오타 등등 불필요한 코드 코드리뷰가 쪼금 이를 수도linter 무엇을 사용하시나요? black isort flake8이전 부스트캠프 기수 진로가 어떤지? 스타트업, 대기업, 대학원 등으로 많이 가셨다 결론은 다른 사람보다 더 열심히 해야지 성공한다다른 분야로 이동 가능성? AI engineer가 모델링만 하지 않는다 결국 서비스를 만들어야되니깐 모든 것을 한다 준비하기 나름이다 보통 DevOps로 많이 간다 (MLOps) airflow docker harbor ci/cd (jenkins, circle ci, github workflow) 생각보다 모델을 변경할 일이 거의 없다성장하기 위해서 알면 좋은 것 part 1 프로그래밍의 대한 기초적인 문법 이해만 한다면, 기 이후부터는 책으로 공부하지 마라 프로젝트를 하나 하는 것이 제일 좋다 GitHub에 좋은 자료들이 많다 Github 팔로우를 많이 해라 다른 사람들이 눌러주는 star를 통해서 현재 유행 파악 가능 문서화를 잘해라 개발은 혼자 절대 안한다 노션을 ToDo랑 Dev Docs로 같이 사용한다 Miscellaneous There is a free logo maker tool that seems really good.Things I Will DoTomorrow Exercise and clean my room in the morning 1 hour of algorithm study 1 hour of research paper reading Continue watching PyTorch lectures and start doing the problem sets Sleep before 2 am 질문을 잘하는 방법 포스트 읽기Down the Line Learn Regular Expression Learn what an API is Learn about Git (Crash Course on Youtube) Read this Study the book, “Mathematics for Machine Learning” (this is the book) Learn about the tools in Github Student Pack Find which company I would want to work for. Learn about DevOpsSummaryThere is not much to talk about today. I was just extremely busy with the assignment." }, { "title": "[boostcamp AI Tech][Day 6] :sunny: + :cocktail: = :fire:", "url": "/posts/day-6/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, pytorch, level 1, week 2, day in review", "date": "2022-09-26 22:00:00 +0900", "snippet": " Men are born to succeed, not fail. - Henry David Thoreau Day in Review PyTorch lectures on boostcourse Phytophotodermatitis… or in plain English, magarita burn Things I Will Do Tomorrow Down the Line SummaryDay in ReviewPyTorch lectures on boostcourseI did not make a lot of progress but I did watch 3 lectures on PyTorch. The first two were basic introduction to the framework and a showcase of its syntax while the last one was on actually looking at a project template. Since it was my first time looking at such code, it was difficult for me to understand everything if any. But it’s okay, repetition always helps.Phytophotodermatitis… or in plain English, magarita burnA few days ago, I woke up in the morning only to realise that I had a one to two centimeter long dark pigmentations on my right ring and pinky fingers. At first, I thought it was some dirt and tried washing it off. I was unsuccessful. And it was soon apparent that the darkening was something under the skin. Fast foward to today, during lunch break, I visited the dermatologist, who not a second after seeing my finger, and most probably my tanned arm, asked whether I went on a holiday recently. I was in disbelief; what has my holiday (which I had returned from at least a month ago) have to do with a pigmentation that occured just a few days ago. But I was also intrigued, and why wouldn’t you not answer a doctor’s question, and so I told him that I had been to Vietnam.His next question was even more bizarre. He asked: did you drink magarita? :joy:What a question. But he was dead serious. I told him that I did, and he went on to explain how exposure to sunlight after getting lime juice on your skin can cause something called phytophotodermatitis, colloquially know as magarita burn. Phyto = plant, photo = light, and dermatitis = inflammation. Basically, a photo-sensitive chemical in lime reacts with the sun while on your skin and it burns you. Apparently, it can be so mild that you don’t really feel anything at all and the “post-inflammatory pigmentation” can occur weeks after which was the case for me. And to lose the color, you just have two wait until your next batch of skin cells which would be in a couple of months.So there you have it. Be mindful of drinking magaritas in the sun and remember the fomula :sunny: + :cocktail: = :fire:.Things I Will DoTomorrow Exercise and clean my room in the morning 1 hour of algorithm study 1 hour of research paper reading Continue watching PyTorch lectures and start doing the problem sets Sleep before 2 am.Down the Line Learn Regular Expression Learn what an API is Learn about Git (Crash Course on Youtube) Read this Study the book, “Mathematics for Machine Learning” (this is the book) Learn about the tools in Github Student Pack Find which company I would want to work for.SummaryI had a great Monday. I am glad that I don’t have skin cancer and I am excited to learn about PyTorch over the course of the week. Tomorrow I will concentrate heavily on lectures." }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 3: PyTorch 프로젝트 구조 이해하기", "url": "/posts/03-pytorch-project/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-26 12:00:00 +0900", "snippet": "개요Going into the Lecture 파이토치의 모듈들이 어떻게 구성되는지 프로젝트 코드들이 어떻게 작동하는지 modules.py, data.py, preprocessor.py 등등ml 코드는 언제나 Jupyter에서? 영원히 세발 자전거를 탈 수 없다 개발 초기 단계에서는 대화식 개발 과정이 유리해서 괜찮다 하지만 배포 및 공유 단계에서는 notebook 공유의 어려움, 실행순서 꼬임과 재현의 제한이 있다다른 사람들이 만들어 놓은 프로젝트 template가 많이 존재한다. 실행, 데이터, 모델, 설정, 로깅, 지표, 유틸리티 등 다양한 모듈들을 분리하여 프로젝트를 템플릿화 우리가 사용할 건 (여기)[http://github.com/victoresque/pytorch-template]" }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 2: PyTorch Basics", "url": "/posts/02-pytorch-basics/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-26 10:00:00 +0900", "snippet": "개요 기초문법이 numpy랑 비슷하다 (numpy + AutoGrad) numpy만 잘 알아도 쉽게 사용이 가능하다 (TensorFlow도 마찬가지) autograd 표현이 조금 다르다 수식들을 어떻게 쓸 수 있는지 소개를 한다.PyTorch OperationsTensor Tensor: 다차원 Arrays를 표현하는 PyTorch Class이다 사실상 numpy의 ndarray와 동일하다 (TensorFlow의 Tensor와도 동일) Tensor를 생성하는 함수도 numpy와 비슷하다Numpy to Tensornumpy:import numpy as npn_array = np.arange(10).reshape(2,5)print(n_array)print(\"ndim :\", n_array.ndim, \"shape :\", n_array.shape)&gt;&gt;&gt; [[0 1 2 3 4] [5 6 7 8 9]] ndim : 2 shape : (2, 5)pytorch:import torcht_array = torch.FloatTensor(n_array)print(t_array)print(\"ndidm :\", t_array.ndim, \"shape :\", t_array.shape)&gt;&gt;&gt; tensor([[0., 1., 2., 3., 4.], [5., 6., 7., 8., 9.]]) ndim : 2 shape : torch.Size([2, 5])Array to Tensor Tenor 생성은 list나 ndarray를 사용할 수 있다 .from_numpy(), .tensor() 또는 .FloatTensor로 생성한다 하지만 주로 다룰 tensor 객체는 거의 없다.data to tensor:data = [[1, 2], [3, 4]]t_data = torch.tensor(data)ndarray to tensor:nd_array_ex = np.array(data)t_array = torch.from_numpy(nd_array_ex)Tensor data types Data Type dtype CPU tensor GPU tensor 32-bit floating point torch.float32 or torch.float torch.FloatTensor torch.cuda.FloatTensor 64-bit floating point torch.float32 or torch.double torch.DoubleTensor torch.cuda.DoubleTensor 16-bit floating point 1 torch.float16 or torch.half torch.HalfTensor torch.cuda.HalfTensor 16-bit floating point 2 torch.bfloat16 torch.BFloat16Tensor torch.cuda.BFloat16Tensor Numpy like operations 기본적으로 numpy의 대부분의 사용법이 그대로 적용된다 .flatten(), torch.ones_like(), .numpy(), .shape(), type 단 cpu 또는 gpu 중 어디에 올렸는지 확인하는 .device attribute과 .to('cuda') 같은 operation이 있다.data = [[1, 2, 3],[4, 5, 6], [7, 8, 9]]x_data = pytorch.tensor(data)x_data[1:]&gt;&gt;&gt; tensor([[4, 5, 6], [7, 8, 9]])x_data[:2, 1:]&gt;&gt;&gt; tensor([[2, 3], [5, 6]])x_data.flatten()&gt;&gt;&gt; tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])torch.ones_like(x_data)&gt;&gt;&gt; tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]])x_data.numpy()&gt;&gt;&gt; array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])x_data.shape&gt;&gt;&gt; torch.Size([3, 3])x_data.device&gt;&gt;&gt; device(type='cpu')if torch.cuda.is_available(): x_data_cuda = x_data.to('cuda')x_data_cuda.device&gt;&gt;&gt; device(type='cuda', index=0)Tensor Handling .view(), .squeeze(), .unsqueeze() 등으로 tensor 조정이 가능하다 .view(): .reshape()과 동일하게 tensor의 shape을 변환한다 .squeeze(): 차원의 개수가 1인 차원을 삭제 (압축) .unsqueeze(): 차원의 개수가 1인 차원을 추가tensor_ex = torch.rand(size = (2, 3, 2))tensor_ex&gt;&gt;&gt; tensor([[[0.2707, 0.2995], [0.9493, 0.3023], [0.2432, 0.2512]], [[0.1613, 0.9063], [0.0365, 0.3489], [0.6682, 0.3997]]])tensor_ex.view([-1, 6])&gt;&gt;&gt; tensor([[0.2707, 0.2995, 0.9493, 0.3023, 0.2432, 0.2512], [0.1613, 0.9063, 0.0365, 0.3489, 0.6682, 0.3997]])a = torch.zeros(3, 2)b = a.view(2, 3)a.fill_(1)&gt;&gt;&gt; tensor([[1., 1.], [1., 1.], [1., 1.]])a&gt;&gt;&gt; tensor([[1., 1.], [1., 1.], [1., 1.]])b&gt;&gt;&gt; tensor([[1., 1., 1.], [1., 1., 1.]])# 2d tensorex = torch.tensor([[1, 2], [3, 4]])ex.unsqueeze(0)&gt;&gt;&gt; [[1, 2], [3, 4]] # dim: 1, 2, 2ex.unsqueeze(1)&gt;&gt;&gt; [[[1,2]], [[3,4]]] # dim: 2, 1, 2ex.unsqueeze(2)&gt;&gt;&gt; [[[1], [2]], [[3], [4]]] # dim: 2, 2, 1 행렬곱셈 연산 함수는 dot이 아닌 .mm 사용 mm과 matmul 차이: matmul은 broadcasting 지원한다n1 = np.arange(10).reshape(2, 5)n2 = np.arange(10).reshape(5, 2)t1 = torch.FloatTensor(n1)t2 = torch.FloatTensor(n2)t1.mm(t2)Tensor operations for ML and DL formula nn.functional` 모듈을 통해 다양한 수식 변환을 지원한다 그냥 필요할 때 찾아보면 된다.import torchimport torch.nn.functional as Ftensor = torch.FloatTensor([0.5, 0.7, 0.1])h_tensor = F.softmax(tensor, dim = 0)y = torch.randint(5, (10, 5))y_label = y.argmax(dim = 1)F.one_hot(y_label)torch.cartesian_prod(tensor_a, tensor_b)AutoGrad PyTorch의 핵심은 자동 미분의 지원 -&gt; .backward() 함수 사용w = torch.tensor(2.0, requires_grad = True)y = w ** 2z = 10 * y + 25z.backward()w.grad&gt;&gt;&gt; tensor(40.)a = torch.tensor([2., 3.], requires_grad=True)b = torch.tensor([6., 4.], requires_grad=True)Q = 3 * a ** 3 - b ** 2external_grad = torch.tensor([1., 1.])Q.backward(gradient = external_grad)a.grad&gt;&gt;&gt; tensor([36., 81.])" }, { "title": "[boostcamp AI Tech][PyTorch] Lecture 1: Intro. To PyTorch", "url": "/posts/01-intro-to-pytorch/", "categories": "boostcamp AI Tech, Week 2 - PyTorch", "tags": "boostcamp, pytorch, level 1, week 2", "date": "2022-09-26 08:00:00 +0900", "snippet": " 이번 주 강의 소개 개요 Computational Graph PyTorch vs Tensorflow Why PyTorch? Pytorch 특징이번 주 강의 소개 딥러닝 이론을 실제로 구현하기 위해 필요한 PyTorch 프레임워크 사용법에 대해 학습한다 기본적인 네트워크 구현 및 데이터 로딩 프로젝트 구조 로깅, Multi GPU, 이어 학습하기 등의 테크닉 부분들개요 PyTroch는 딥러닝 framework 딥러닝을 바닥부터 짠다? -&gt; 죽을 수도 있다… 뷰노 의료 AI 스타트업, 한동대 등 프레임워크를 직접 개발한 적은 있지만 메인 프레임워크로 올라가기에는 한계가 있다 만약에 프레임워크가 어떻게 개발되는지 관심이 있다면 밑바닥부터 시작하는 딥러닝 3을 추천한다 지금은 남이 만든 걸 사용한다 자료도 많고 관리도 잘되고 표준이라서… leading framework으로 facebook의 PyTorch하고 Google의 TensorFlow가 있다 두 프레임워크는 computational graph에 차이가 있다   Keras TensorFlow PyTorch Level of API high-level API both high and low level APIs Lower-level API Speed Slow High High Architecture Simple, more readable and concise Not very easy to use Complex Debugging No need to debug Difficult to debug Good debugging capabilities Dataset Compatibility Slow &amp; Small Fast speed &amp; large Fast speed &amp; large datasets Uniqueness Multiple back-end support Object Detection Functionality Flexibility &amp; Short Training Duration Created by Not a library on its own Google Facebook Ease of Use User-friendly Incomprehensive API Integrated with Python Compuational graphs used Static Graphs Statich Graphs Dynamic Computation Graphs Computational Graph 연산의 과정을 그래프로 표현한다 Define and Run (Static): 그래프를 먼저 정의하고 실행시점에 데이터를 feed한다 Build graph once, then run many times Define by Run (Dynamic Computational Graph, DCG): 실행을 하면서 그래프를 생성하는 방식 Each forward pass defines a new graph (easy to debug) DCG가 느릴 것 같지만 사실 그렇지 않고 “느낌상” DCG가 더 빠르고 편한게 있다. PyTorch vs Tensorflow Tensorflow는 구글의 도음을 받아 production, cloud multi-GPU 등의 장점이 있다 Pytorch는 debugging이 더 쉬워서 research에서 더 많이 활용이 된다Why PyTorch? Define by Run의 장점 즉시 확인 가능, pythonic code GPU support, Good API and community 사용하기 편한 장점이 가장 크다Pytorch 특징 Numpy 구조를 가지는 Tensor 객체로 array 표현한다 자동미분(autograd)을 지원하여 DL 연산을 지원한다 다양한 형태의 DL을 지원하는 함수와 모델을 지원한다." }, { "title": "[boostcamp AI Tech][Day 5] End of the first week", "url": "/posts/day-5/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ai math, level 1, week 1, day in review", "date": "2022-09-23 10:00:00 +0900", "snippet": " Imagination is the one weapon in the war against reality.. - Jules de Gaultier Things I Did Today Things I Will Do Monday Down the Line Day in ReviewThings I Did Today I was lazy so here is a brief overview of what I did today. Review the earlier lectures on boostcourse Joined the “office hour by mentors” who went through the difficult problem sets.Things I Will DoMonday Exercise and clean my room in the morning 1 hour of algorithm study 1 hour of research paper reading Write notes for the earlier lectures Sleep before 2 am.Down the Line Learn Regular Expression Learn what an API is Learn about Git (Crash Course on Youtube) Read this Study the book, “Mathematics for Machine Learning” (this is the book) Learn about the tools in Github Student Pack Find which company I would want to work for.Day in ReviewIt was an okay day." }, { "title": "[boostcamp AI Tech][Day 4] Day in Review", "url": "/posts/day-4/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ai math, level 1, week 1, day in review", "date": "2022-09-22 22:00:00 +0900", "snippet": " The computing field is always in need of new cliches. - Alan Perlis Things I Did Master Class by Sungbin Lim 수학 너무 어려워요… 쉽게 공부하는 방법이 있나요? 여러 모델들의 수학적 원리를 모두 이해하고 있어야 하나요? ML 엔지니어는 수학을 어느 정도 알아야 할까요? 엔지니어는 어떤 사람일까? 인공지능 분야에서 대학원이 필수일까요? 교수님이 쌓아오신 커리어와, 그 방향을 결정하는데 중요하게 생각하셨던 점이 무엇인지 궁금합니다 Extra Miscellaneous Multiple Cursors in VS Code My notes location Things I Will Do Tomorrow Down the Line Day in ReviewThings I DidMaster Class by Sungbin Lim수학 너무 어려워요… 쉽게 공부하는 방법이 있나요? 머리로 하지말고 손으로 익히는게 좋다 용어의 정의는 일단 외우는 것부터 시작하자 교과서나 위키피디아를 활용하면 좋다 만일 용어 사용이 헷갈린다면 인공지능 커뮤니티에 물어보기. 여러 모델들의 수학적 원리를 모두 이해하고 있어야 하나요? 모두 이해하는 것은 어렵지만 적어도 원리를 이해하는데 필요한 기초는 갖춰야 합니다 선형대수/확률론/통계학은 꼭 알아두기 이론을 공부해서 논문을 쓸 게 아니라면 해석학/위상수학까지 공부할 필요는 없다 기초 내용만 공부하기보다 머신러닝에서 어떻게 활용되는지 검색해보기 예) 분류 문제에서 왜 cross-entropy를 손실함수로 사용하는가? 예) 경사하강법을 쓰는 것보다 미니배치 SGD를 쓰는게 왜 학습에 더 효율적인가? ML 엔지니어는 수학을 어느 정도 알아야 할까요? 필요한 걸 공부해서 빠르게 따라잡을 수 있을 만큼은 알아야 한다.엔지니어는 어떤 사람일까? astronaut처럼 직접 현장에서 문제를 해결하는 사람 문제를 정의하고 -&gt; 정보를 모아서 솔루션을 구하고 -&gt; 기술적으로 구현하고 -&gt; 결과를 테스트하고 문서화 Define -&gt; Brainstorm -&gt; Implement -&gt; Analyze 수학은 Define, Brainstorm할 때 필요.인공지능 분야에서 대학원이 필수일까요? 필수는 아닌데 본인이 관심을 가진 분야가 새로운 분야라면 대학원을 추천합니다 아래 Hype Cycle 참고하기. 도메인마다 요구하는게 다르다.교수님이 쌓아오신 커리어와, 그 방향을 결정하는데 중요하게 생각하셨던 점이 무엇인지 궁금합니다 문과인데 수학을 복수정공함 공학과 선배들, 주변 사람들과 교류를 많이 하면서 배웠다 롤모델이 생기면 그 사람을 따라서 성장했다Extra 특기를 만들어라 솔직히 말하면 머신러닝 인력 시장이 좋지 않다 실력있는 인공지능 인력은 아직도 부족하다 (문제해결 능력) 특정 회사를 목표로 준비해라 필요로 하는 스킬셋을 키워라. MiscellaneousMultiple Cursors in VS Code Use the mouse and click anywhere you want to while holding Alt to add another cursor Press Ctrl + Alt + Up/Down to add new cursors above or below After highlighting a text, press Ctrl + D to select the next occurance of the selected word (and repeat to select as many as you like). Or you can simply press Ctrl + Shift + L to sellect all occurances of the current selection.My notes locationI’ve finally decided on my posts layout and location.I will use Github Pages to upload (1) my notes on lectures and (2) my day in review where I will write about anything else I learnt on that day, my plan for tomorrow and the nearby future and finally my day in review itself.And I will use Notion to catalog my research paper reading and review and notes on any special seminars and lectures we might have and provide a link in my day in review post on Github Pages.Things I Will DoTomorrow Exercise in the morning 1 hour of algorithm study 1 hour of research paper reading Write notes for the earlier lectures Sleep before 2 am.Down the Line Start preparing for coding tests Learn Regular Expression Learn what an API is Learn about Git (Crash Course on Youtube) Read this Study the book, “Mathematics for Machine Learning” (this is the book) Learn about the tools in Github Student Pack Find which company I would want to work for.Day in ReviewRight now, the problem is not a lack of information but the polar opposite - there is an information overload. I am constantly finding new information online and through other campers and mentors but there is not enough time to process all of it, if any. So, my highest priority right now is devising a study plan. My first idea is to have an hour of algorithm study, an hour of research paper reading and the rest on the lectures published on boostcourse and using my spare time to learn about other things. And whenever I am on the subway, I will reread my posts for revision. Let’s do it! :fire::fire::fire:" }, { "title": "[boostcamp AI Tech][AI Math] Lecture 10: RNN 첫걸음", "url": "/posts/day-4-rnn/", "categories": "boostcamp AI Tech, Week 1 - AI Math", "tags": "boostcamp, ai math, level 1, week 1", "date": "2022-09-22 10:00:00 +0900", "snippet": "TOC Going into the Lecture 시퀀스 데이터 다루기 Recurrent Neural Network을 이해하기 RNN의 역전파: Backpropagation Through Time(BPTT) BPTT를 좀 더 살펴보기 Going into the Lecture CNN과 다르게 시계열(time series), sequence 데이터에 주로 적용이 되는 network이다 소리, 문자열, 주가 등의 데이터를 스퀀스(sequence) 데이터로 분류한다 독립동등분포(i.i.d) 가정을 따르지 않을 때가 많으므로 주의해야하다 개가 사람을 물었다와 사람이 개를 물었다는 다른 의미를 가지고 있다 모델 설계는 어렵지 않지만 왜 이렇게 설계를 해야하는지 이해가 필요하다.시퀀스 데이터 다루기 이전 시퀀스의 정보를 가지고 앞으로 발생할 데이터의 확률분포를 다루기 위해 조건부확률을 이용한다\\[\\begin{align}P(X_1, ..., X_t) &amp; = P(X_t | X_1, ... X_{t-1})P(X_1, ..., X_{t-1}) \\\\&amp; = P(X_t | X_1, ... X_{t-1})P(X_{t-1}|X_1, ..., X_{t-2})P(X_1, ..., X_{t-2}) \\\\&amp; = \\prod_{s=1}^{t}P(X_s | X_{s-1}, ..., X_1)\\end{align}\\] 과거의 모든 데이터가 필요한 것은 아니다 시퀀스 데이터를 다루기 위해선 길이가 가변적인 데이터를 다룰 수 있는 모델이 필요하다\\[\\begin{aligned}X_{t} &amp;\\sim P(X_t | X_{t-1}, ..., X_1) \\quad\\quad \\\\X_{t+1} &amp;\\sim P(X_{t+1} | X_{t}, X_{t-1}, ..., X_1) \\end{aligned}\\] $X_1$ 까지가 아닌 고정된 길이 $\\tau$ 만큼의 시퀀스만 사용하는 경우 $AR(\\tau)$ (Autoregressive Model) 자기회귀모델이라고 부른다. $\\tau$ 는 hyperparameter이다. 즉 모델링하기 전에 우리가 정해 줘야하는 변수이며 문제에 따라서 $\\tau$ 가 바뀔 때가 있고 이런 경우에 사용되는 방법이 RNN의 기본 모형인 Latent Autoregressive Model(잠재자기회기 모델)이다. 과거 바로 이전의 정보를 제외한 나머지 정보들을 $H_t$ 라는 잠재변수로 인코딩해서 활용하는 잠재 AR 모델이다 기리가 가변적이지 않고 고정된 길이의 데이터를 가지고 모델링을 할 수 있는 장점이 있 과거의 정보들의 잠재 변수를 어떻게 인코딩할지가 선택의 문제. 이를 해결하는게 RNN이다. Recurrent Neural Network을 이해하기 가장 기본적인 RNN 모형은 MLP와 유사한 모양이다.\\[\\begin{aligned}\\mathbf{H}_t &amp;= \\sigma(\\mathbf{X}_t\\mathbf{W}^{(1)}_{X} + \\mathbf{H}_{t-1}\\mathbf{W}^{(1)}_{H} + \\mathbf{b}^{(1)}) \\\\\\mathbf{O} &amp;= \\mathbf{HW}^{(2)} + \\mathbf{b}^{(2)} \\quad\\quad\\quad\\quad\\quad\\quad\\quad \\\\ \\end{aligned}\\] 이전 순서의 잠재변수($H_{t-1}$)와 현재의 입력($X_t$)을 활용하여 모델링한다.RNN의 역전파: Backpropagation Through Time(BPTT) 빨간색 화살표가 역전파. 잠재변수에 두 변수가 들어옴 다음 시점에서의 잠재변수에서 들어오는 gradient vector 출력에서 들어오는 gradient vector 출력도 2곳이다 입력 이전 시점의 잠재변수. BPTT를 좀 더 살펴보기 BPTT를 통해 RNN의 가중치행렬의 미분을 계산해보면 미분의 곱으로 이루어진 항이 계산된다. 손실함수는 아래와 같다.\\[L(x, y, w_h, w_o) = \\sum_{t = 1}^{T}l(y_t, o_t) \\quad\\quad h_t = f(x_t, h_{t-1}, w_h) \\text{ and } o_t = g(h_t, w_o)\\\\\\] 편미분을 잘하면 아래와 같은 결과가 나온다.\\[\\partial_{w_{h}}L(x, y, w_h, w_o) = \\sum_{t=1}^{T}\\partial_{w_h}l(y_t, o_t) = \\sum_{t=1}^T\\partial_{o_t}l(y_t, o_t)\\partial_{h_t}g(h_t , w_h)[\\partial_{w_h}h_t]\\\\\\]\\[\\partial_{w_h}h_t = \\partial_{w_h}f(x_t, h_{t-1}, w_h) + \\sum_{i=1}^{t-1}\\left( \\prod_{j=i+1}^{t} \\partial_{h_{j-1}}f(x_j, h_{j-1}, w_h)\\partial_{w_h}f(x_i, h{i-1}, w_h) \\right)\\] 현재 시점부터 예측이 끝나는 $t$시점까지 시퀀스의 길이가 길어질수록 $\\prod_{j=i+1}^{t} \\partial_{h_{j-1}}f(x_j, h_{j-1}, w_h)$은 불안정해지기 쉽다. 1 보다 크면 폭발, 1 보다 작으면 기울기가 되게 작어진다 작아질 때를 기울기 소실(vanishing gradient)이라고 한다 기울기 소실를 해결하기 위해 truncated BPTT를 사용한다 시퀀스 길이를 끊는 것 하지만 완벽한 해결책은 아니다 그래서 LSTM이나 GRU가 등장했다. " }, { "title": "[boostcamp AI Tech][AI Math] Lecture 9: CNN 첫걸음", "url": "/posts/day-4-cnn/", "categories": "boostcamp AI Tech, Week 1 - AI Math", "tags": "boostcamp, ai math, level 1, week 1", "date": "2022-09-22 10:00:00 +0900", "snippet": " Convolution 연산 이해하기 기존에 배운 MLP 연산 CNN 연산 다양한 차원에서의 Convolution 2차원 Convolution 연산 이해하기 Convolution 연산의 역전파 이해하기Convolution 연산 이해하기기존에 배운 MLP 연산 지금까지 배운 다층신경망(MLP)은 fully connected 구조였기 때문에 $h_i$를 구할 때 $W_i$가 항상 필요. 학습을 해야하는 parapeter의 숫자가 너무 커지게 됨. \\[h_{i} = \\sigma\\left( \\sum_{j=1}^{p} W_{ij}x_{j} \\right)\\]CNN 연산\\[h_{i} = \\sigma\\left( \\sum_{j=1}^{p} V_{ij}x_{j} \\right)\\] convolution 연산은 기존의 $W$ 가중치 행렬을 사용하지 않고 $V$ 라는 kernel 행렬을 활용함 (선형변환의 한 종류) 고정된 kernel을 입력 백터 $x$가 움직이며 계산이 됨 Parameter size를 많이 줄일 수 있음 Convolution 연산의 수학적인 의미는 커널을 신호(signal)를 이용해 국소적(locally)으로 증폭 또는 감소시켜서 정보를 추출 또는 필터링하닌 것.\\[\\begin{aligned}\\text{continuous} \\quad [f * g](x) = \\int_{\\mathbb{R}^d}f(z)g(x + z)dz = \\int_{\\mathbb{R}}f(x + z)g(z)dz = [g * f](x) \\\\\\text{discrete} \\quad [f * g](x) = \\sum_{a\\in\\mathbb{Z}^{d}}f(a)g(i + a) = \\sum_{a\\in\\mathbb{Z}^{d}}f(i + a)g(a) = [g * f](i) \\quad\\quad\\end{aligned}\\] CNN에서 사용되는 연산은 사실 convolution이 아니고 cross-correlation이라고 부름. kerenl의 2가지 특징: Translation invariant: 정의역 내에서 움직여도 변하지 않음 locality: 주어진 신호를 국소적으로 적용 영상처리에서 convolution의 역활을 확인해보자다양한 차원에서의 Convolution 데이터의 성격에 따라 사용하는 커널이 달라짐 $i,~j,~k$가 바뀌어도 커널 $f$의 값은 바뀌지 않는다.2차원 Convolution 연산 이해하기 2D-Conv 연산은 커널을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조다. 각 행렬값을 입력값에 elementw-wise 곱셈을 해서 연산을 한다 출력의 크기가 당연히 줄어든다.\\[\\begin{aligned}O_{H} = H - K_{H} + 1 \\; \\\\ O_{W} = W - K_{W} + 1\\end{aligned}\\]e.g. 입력 데이터의 크기가 28 x 28이고 3 x 3 커널로 convolution되면 26 x 26이 된다. 채널이 여럭개인 2차원 입력의 경우 2차원 Convolution을 채널 개수만큼 적용한다고 다 더해서 출력한다 3차원부터는 행렬이 아닌 텐서(Tensor)라 부른다. 만약에 채널이 여러개인 출력을 원한다면 커널을 그만큼 적용하면 된다.Convolution 연산의 역전파 이해하기 Convolution 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 convolution 연산이 나오게 된다.\\[\\begin{aligned}\\begin{matrix} \\frac{\\partial}{\\partial x}[f * g](x) &amp;=&amp; \\frac{\\partial}{\\partial x}\\int_{\\mathbb{R}^{d}}f(y)g(x-y) dy \\\\ &amp;=&amp; \\int_{\\mathbb{R}^{d}}f(y)\\frac{\\partial g}{\\partial x}(x - y)dy \\\\ &amp;=&amp; [f * g'](x)\\end{matrix}\\end{aligned}\\]" }, { "title": "[boostcamp AI Tech][Day 3] First Mentor Session and VS Code Extensions", "url": "/posts/day-3/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ai math, level 1, week 1", "date": "2022-09-21 10:00:00 +0900", "snippet": " The computing field is always in need of new cliches. - Alan Perlis Things I Did Peer Session Derivative of the Mean Square Error (MSE) (Incomplete) The difference between Gradient Descent(GD) and Stochastic Gradient Descent(SGD) Batch Size, Epoch, Iteration Epoch Batch Size Then what is a batch? Iterations Miscellaneous Useful VS Code shortcuts I learned today Here are some VS Code extensions I installed today Things I Will Tomorrow Down the Line Day in ReviewThings I DidPeer SessionDerivative of the Mean Square Error (MSE) (Incomplete)Firstly, let’s talk about linear regression. Acording to Wikipedia: In statistics, linear regression is a linear approach for modelling the relationship between a scalar reponse and one or more explanatory variable. The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression.The difference between Gradient Descent(GD) and Stochastic Gradient Descent(SGD)In both GD and SGD, you update a set of parameters in an iterative manner to minimize an error funcion.While in GD, you have to run through all the samples in your training set to do a single update for a parameter in a particular iteration. In SGD, on the other hand, you use only one or subset of training sample from your training set to do the update for a parameter in a particular iteration. If you use a subset, it’s called Minibatch Stochastic Gradient Descent.Thus, if the number of training samples are large, in fact very large, then using gradient descent may take too long because in every iteration when you are updating the values of the parameters, you are running through the complete training set. On the other hand, using SGD will be faster because you use only one training sample and it starts improving itself right away from the first sample. (Source)Batch Size, Epoch, IterationEpochOne epoch is when an ENTIRE dataset is passed forward and backward through the neural network once.Batch SizeBatch size is the total number of training examples present in a single batch.Then what is a batch?It’s the partions of the dataset that were divided.IterationsIterations is the number of batches needed to complete one epoch. $dataset = number~of~batches \\times iterations$ MiscellaneousUseful VS Code shortcuts I learned today Ctrl + K, V = Markdown: open preview to the side (and now that I’ve installed Mardown All in One, it also closes it if it’s open) I was actually using MarkdownPad 2 to write in a Onedrive folder and then copied it to the Github Page folder for some reason. What an unoptimal workflow Ctrl + K, Z = Zen Mode: basically one-ups F11. It removes even more clutter that you only see the coding page.Here are some VS Code extensions I installed today Markdown All in One: this seems like the ultimate extension for Markdown. It has so many features: Keyboard shortcuts such as Ctrl + B to toggle bold Ctrl + I to toggle italics Ctrl + Shift + [ or ] to toggle heading (downlevel or uplevel) Automatically table of contents: just run the command “Create Table of Contents” in VS Code Command Palette and see magic List editing that uses Enter, Tab, Backspace keys to add and indent lists deeper or shallower. Table Foramtter by the shortcut Alt + Shift + F Math by using Markdown+Math extension Auto completions Ability to paste link on selected text And ability toggle “Open Preview” shortcut. Paste Image: this extension paste image directly (Ctrl + Alt + V) from clipboard to Markdown and saves the image in the folder that contains the current editing file. I actually had some trouble with the settings but I managed in the end. I better learned how this Jekyll thing works at least. Markdown Emoji: because who doesn’t like emjois. Adds support for :emoji: syntax to VS Code’s built-in markdown preview :+1: :smile: :carrot: :rocket: :cry: Adds support for :emoji: to markdown cells in VS Code’s notebooks. I was very pleasantly surprised how there are so many free open source extensions on VS Code to improve productivity and functionality to the software. It’s no wonder why so many people recommend VS Code. It’s an eco-system that you can’t code without once you’ve set it up and personalized it.Things I WillTomorrow Watch the later lectures on Boostcourse Exercise in the morning Study the book, “Mathematics for Machine Learning” (this is the book)Down the Line Start preparing for coding tests Read some research papers Learn Regular Expression.Day in ReviewIt was another decent day. We had an “Introduce your Team” Zoom meeting in the morning and I spent the entire afternoon installing VS Code extensions and setting it up. I’ve started to get the hang of Markdown and Github Pages as well. Then in the evening, we had our first mentor session. Our mentor was energetic and inspirational. He provided us with tons of priceless information and I got to better understand what I have to do (and there is a lot of it). The following five months will be an interesting joruney." }, { "title": "[boostcamp AI Tech][Day 2] Markdown Syntax and AI Math", "url": "/posts/day-2/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ai math, level 1, week 1", "date": "2022-09-20 10:00:00 +0900", "snippet": " I do not fear computers. I fear the lack of them - Isaac AsimovLearn about MarkdownWhat is Markdown?According to the creator himself, John Gruber, Markup is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML).His philosophy is to emphasize two things: readability and “write-ability”.Below is me (nearly completely) paraphrasing the syntax guide in the creator’s website.HeadersTo set headers you can do this (Setext-style):This is H1==========This is H2----------But I prefer (atx-style):# This is H1## This is H2 ##### This is H3#### This is H4##### This is H5You can “close” atx-style headers but this is purely cosmetic. (The closing hashes don’t even need to mach the number of hashes used to open the header!)BlockquotesMarkdown uses email-style &gt; characters for blockquoting. Apparently it looks best if you put a &gt; before every line: so this is what it looks likeBlockquotes can be nested by adding additional &gt;: First level of quoting second level and the third And they can contain other Markdown elements, including headers, lists, and code blocks: This is a header. This is the first list item. This is the second list item. Here’s some example code: return shell_exec(\"echo $input | $markdown_script\"); ListsMarkdown supports ordered (1. 2. 3.) and unordered lists (*, + or -).* First* Second+ Third- FourthAnd ordered lists use numbers followed by periods:1. Robin2. Mayya3. KisaNote that the actual numbers you use have no effect on the HTML output Markdown produces.You can also do weird things: A list item with a blockquote: This is a blockquoteinside a list item. A list item with a code block: &lt;code goes here&gt; (you need to indent twice!) Code BlocksThe lines of a code block are interpreted literally. Markdown wraps a code block in both &lt;pre&gt; and &lt;code&gt;. Just indent once and you are good to go.here is a line of code. Just note that you need a blank line above. You don't need a blank line below but it probably looks nice while you work to have one.Horizontal RulesYou can produce horizontal rule tag (&lt;hr /&gt;) by placing three or more hyphens, asterisks, or underscores on a line by themselves.* * *********- - ----------------LinksMarkdown supports two style of links: inline and reference. In both styles, the link text is delimited by [square brackets].Typing this:This is [an example](http://example.com/ \"Title\") of an inline link[This link](http://example.com/) has no attribute.will result in:This is an example of an inline link.This link has no attribute.***If you are referring to a local resource on the same server, you can use relative paths:See my [About](/about/) page for details.Reference-style links use a second set of square brackets, inside with you place a label of your choosing to identify the link:This is [an example][id] of a reference-style link.Then, anywhere in the document, you define your link label like this, on a line by itself:[id]: http://example.com/ \"Optional Title Here\"EmphasisMarkdown treats (*) and underscores(_) as indicators of emphasis. Text wrapped with one of the indicators will be wrapped with an HTML &lt;em&gt; tag, a double will be wrapped with an HTML &lt;strong&gt; tag.*single asterisks*_single underscore_**double asterisks**__double underscores__CodeTo indicate a span of code, wrap it with backtick quotes (`). Unlike a pre-formatted code block, a code span indicates code within a normal paragraph.Use the `print()` functionImagesMarkdown uses an image syntax that is intended to resemble the syntax for links, allowing for two styles: inline and reference.Inline image syntax looks like this:![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg \"Optional Title\")That is: An exclamation mark: ! followed by a set of square brackets, containing the alt attribute text for the image followed by a set of parentheses, containing the URL or path to the image, and an optional title attribute enclosed in double of single quotes.Reference-style image syntax looks like this:![Alt text][id][id]: url/to/image \"Optional title attribute\"MiscellaneousAutomatic linksSimply surround the URL or email address with angle brackets. http://example.com/ and address@example.com was made by typing:&lt;http://example.com/&gt; and &lt;address@example.com&gt;Backslash EscapesMarkdown allows you to use backslash escapes to generate literal characters which would otherwise have special meaning in Markdown’s formatting syntax.Markdown provides backslash escapes for the following characters:\\ backslash` backtick* asterisk_ underscore{} curly braces[] square brackets() parentheses# hash mark+ plus sign- minus sign (hyphen). dot! exclamation markRound UpAnd that’s it! Basically copying word for word the syntax guide really helped me better understand how to use Markdown to its fullest. I highly recommend anyone else who are getting into Markdown to do the same. Again, here’s the link to the syntax guide. Just note that if you Markdown doesn’t support certain elements you can just use the HTML notation. For example, Markdown doesn’t support Highlight element so you can write &lt;mark&gt;this is highlighted&lt;/mark&gt; to get this is highlighted.PandasI watched the lectures on Pandas. I’ve never used the library much so everything was pretty new to me. I think it’s one of those things where you just have to start a project using the library to get a feel of it; there is a limit to how much you can learn just in a lecture, jotting down notes.Here is the link to my notes.MiscellaneousUseful VS Code shortcuts I learned today Ctrl + Space = Trigger Suggest. It pops down the suggestion thingy Ctrl + Shift + Space = Trigger Parameter Suggest. When your cursor is in between the parenthesis of a function, it shows a simple documentation of the function.Python @ is a binary operation for matrix multiplication if it is in the middle of the line) and is a class or a function *decorator** if it is at the start.Things I Will DoTomorrow There is the team introductory presentation in the morning Study the book, “Mathematics for Machine Learning” (this is the book) Watch the later lectures on Boostcourse Exercise in the morning Use the Time Timer clock.Down the Line Start preparing for coding tests Read some research papers Regular Expression.Day in ReviewIt was a good second day into the program. I studied well and there is a lot to learn. I’ll take them one by one. I’m slowly figuring out how to streamline my work-flow and my note-taking and publishing. I think it’s a good idea to create separate Jupyter Notebooks for the lectures I watch. Not sure whether I’ll just provide links here like I did today or rewrite it. We’ll see.The capture card I bought to connect my Canon M50 mark II to the computer just simply died on me. Firstly, it started to not recognize sound and then after a while it pushed out a very distorted fuzzy video footage as if it was some weird filter. Then finally, it would output just a black screen. Luckily, Coupang makes it easy to return faulty product (albeit rather too easily) so I requested a replacement." }, { "title": "[boostcamp AI Tech][Day 1] Start of Boostcamp AI Tech 4기", "url": "/posts/day-1/", "categories": "boostcamp AI Tech, Day in Review", "tags": "boostcamp, ai math, level 1, week 1", "date": "2022-09-19 22:00:00 +0900", "snippet": " And Boostcamp begins :rocket: Things I Did MT Zoom Orientation (Video On &amp; Mic Off) Basic Assignments and Quizzes First Peer Session Things I Will Do Tomorrow Down the Line Day in ReviewThings I DidMT Zoom Orientation (Video On &amp; Mic Off)This took up nearly the entire morning. We, the ‘campers’, were introduced to the camp by the organizers, mentors and TAs. They covered the basic guidelines of dos and don’ts, what’s expected of us and how to “check-in” and “check out” and other frequently asked questions.Basic Assignments and QuizzesAfter lunch, since I had covered all the lectures for this week ahead of time, I went straight to work on the assignments and quizzes that were published today. There were three assignments. First was on making simple Python functions of basic math fuctions like max, min and sum. Second and Third were on text processing like capitalization, digit to word and changing underscore case to camel case. And the quizzes were basically pop quizzes on the lectures we had to watch.First Peer SessionAt 4 pm, I had my first peer session. It was of course a bit awkward at first but with some self-introduction and equally awkward zoom-meeting crashes by a few organizers and mentors, the air became a little lighter and breathable. We were given a task to make a little presentation about our team by Wednesday morning so we had things to discuss. We chose our team name, team’s characteristics, our ground rules and so on.Things I Will DoTomorrow Figure out how to use Github Pages better, how to format my posts to my satisfaction and learn how to use links, highlight, and such Study the book, “Mathematics for Machine Learning” (this is the book) Watch the later lectures on Boostcourse that were more tricky Exercise in the morning Use the Time Timer clock.Down the Line Start preparing for coding tests Read some research papers.Day in ReviewIt was a decent day. I was not that productive but it is understandable considering that it was the first day of school. Now that I mention “school”, it is interesting how different education looks in 2022. I’m sure that nothing will beat face-to-face traditional teaching at school but online education has improved so much with so many supporting tools (Zoom, Stack, HD video streaming and even Gather Town) that I think there are enough genuinely good reasons for an educational body to choose online over offline.I will have to work hard to get the most out of the camp. My goal for now is to make myself hire-able by the end of the camp and get a job. There is so much to do but I will take it one at a time." }, { "title": "[boostcamp AI Tech][Python] Lecture 3: Python Data Structure, Pythonic Code and OOP", "url": "/posts/day-1-lecture-3/", "categories": "boostcamp AI Tech, Week 1 - Python", "tags": "boostcamp, python, level 1, week 1", "date": "2022-09-19 11:00:00 +0900", "snippet": " Python Data Structure 데이터 구조 생각해보기 기본 데이터 구조 Stack(스택) Queue(큐) Tuple(튜플) Set(집합) Dictionary(사전) collections deque OrderedDict defaultdict Counter namedtuple Pythonic Code Overview split &amp; join list comprehension enumerate &amp; zip lambda &amp; map &amp; reduce Iterable Objects Generator Function passing argument keyward arguments default agrumenets asterix Python Data Structure데이터 구조 생각해보기 전화번호부 정보는 어떻게 저장하면 좋을까? 은행 번호표 정보는 어떻게 처리하면 좋을까? 서적 정보는 어떻게 관리하면 좋을까? 창고에 쌓인 수화물의 위치를 역순으로 찾을 때?기본 데이터 구조 스택과 큐 튜플과 집합 사전 Collection 모듈Stack(스택) 벽돌 쌓기: 나중에 넣은 데이터를 먼저 반환하도록 설계된 메모리 구조 Last In First Out (LIFO) data 입력: Push (.append()) data 출력: Pop (.pop())Queue(큐) First In First Out(FIFO) 줄서기~ data 입력: .append() data 출력: .pop(0)Tuple(튜플) 값의 변경이 불가능한 리스트 데이터 변환 외에 리스트의 연산, 인덱싱, 슬라이싱 같은 operation이 가능하다. 변경tuple_example = (1, 2, 3)Set(집합) 값을 순서없이 저장하고 중복 데이터가 불가능하다 .union(), .intersection(), .difference()를 사용해서 집합 연산이 가능하다. s = set([1,2,3,4,5])Dictionary(사전) 데이터를 저장 할 때는 구분 지을 수 있는 값을 함께 저장한다 (key: value) 언패킹이 가능하다.shopping_list = {\"apple\": 5, \"pumpkin\": 1, \"fanta\": 2}item, number = shopping_listcollections List, Tuple, Dict에 대한 Python Built-in 확장 자료 구조(모듈) 편의성, 실행 효율 등을 사용자에게 제공한다 deque, Counter, OrderedDict, defaultdict, namedtuple같은 모듈이 존재한다.deque stack과 queue를 지원하는 모듈 리스트에 비해 빠른 자료 저장 방식을 지원한다 (리스트 함수 모두 지원) rotate(), reverse등 linked list의 특성을 지원한다OrderedDict Dict와 달리, 데이터를 입력한 순서대로 dict를 반환한다 하지만 python 3.6부터 그냥 dict도 입력한 순서를 유지해서 출력을 해준다defaultdict Dict type의 값에 기본 값을 지정, 신규값 생성시 사용하는 방법 그냥 dict는 key값이 존재하지 않으면 error 반환하는데 defaultdict는 기본 값을 반환from collections import defaultdictd = defaultdict(lambda: 0)d['first']Counter Sequence type의 data element들의 갯수를 dict 형태로 반환한다 set의 연산들을 지원한다 +: 더하기 &amp;: intersect |: union from collections import Counterball_or_strike = [\"b\",\"s\",\"b\",\"b\",\"b\",\"s\"]c = Counter(ball_or_strike) # new counter from an iterablec# output: Counter({'b' : 4, 's' : 2})d = Counter({'red' : 4, 'blue' : 2}) # a new counter from mappingprint(list(c.elements()))# output: ['red','red','red','red','blue','blue']c = Counter(cats=2, dogs=1) # a new counter from keyword argsprint(list(c,elements()))# output: ['cat','cat','dog']namedtuple Tuple 형태로 Data 구조체를 저장하는 방법from collections import namedtuplePint = namedtuple('Point', ['x', 'y'])p = Point(11, y = 22)x, y = p # unpackingprint(x + y)# output: 33Pythonic CodeOverview 파이썬 스타일의 코딩 기법 파이썬 특유의 문법으로 코드를 표현 고급 코드를 작성 할수록 더 많이 필요해졌다.split &amp; join string type의 값을 기준값으로 나눠서 list 형태로 변환items = 'zero one two three'.split() # 빈칸을 기준으로 나누기print(items)# output: ['zero', 'one', 'two', 'three']example = 'python,java,javascript'example.split(\",\")# output: ['python', 'java', 'javascript']a, b, c = example.split(',') # unpacking도 가능colors= ['red', 'blue']'-'join(colors)# output: 'red-blue'list comprehension 기존 list를 사용해서 간단히 다른 list를 만드는 방법 for + append 보다 속도가 빠르다result = [i for i in range(10) if i % 2 == 0]result# output: [0, 2, 4, 6, 8]enumerate &amp; zip enumerate: list의 element를 추출할 때 index와 같이 추출된다.for index, value in enumerate(['tic', 'tac', 'toe']): print(i, v) zip: 두 개의 list의 값을 병렬적으로 추출한다.alist = [1,2,3]blist = [4,5,6]for a, b in zip(alist, blist): print(a,b)lambda &amp; map &amp; reduce lambda: 함수 이름 없이 함수처럼 쓸 수 있는 익명함수이다 python 3부터는 권장하지 않으나 아직도 많이 사용한다. f = lambda x, y : x + yprint(f(1,4)) map(f, list): f함수에 list를 매핑해준다. 두 개 이상의 list에도 적용 가능하며 if filter도 사용 가능하다. reduce(f, list): map과 달리 list에 똑같은 함수를 적용해서 sum해준다.from functools import reducereduce(lambda x, y: x + y, [1,2,3,4,5])# output: 15Iterable Objectsiter_obj = iter(['Seoul', 'Busan', 'Jeju'])print(next(iter_obj))# output: 'Seoul'Generator iterable object를 특수한 형태로 사용해주는 함수이다 element가 사용되는 시점에 값을 메모리에 반환한다 yield를 사용해 한번에 하나의 element만 반환한다 값을 메모리에 안올려놓고 메모리에 주소값만 가지고 대기를 하고 있다가 요구할 때 데이터를 호출한다 메모리 주소를 절약할 수 있다 특히 대용량의 데이터를 쓸 때 중요하다.def generator_list(value): result = [] for i in range(value): yield i generator comprehension: list comprehension과 유사한 형태로 generator형태의 list 생성 generator expression expression이라는 이름으로도 부름 [] 대신 ()를 사용하여 표현한다.gen_ex = (n*n for n in range(500))Function passing argumentkeyward arguments 함수에 입력되는 parameter의 변수명을 사용, arguments를 넘긴다default agrumenets parameter의 기본 값을 사용, 입력하지 않을 경우 기본값 출력asterix" }, { "title": "[boostcamp AI Tech][Python] Lecture 2: Basic Python", "url": "/posts/day-1-lecture-2/", "categories": "boostcamp AI Tech, Week 1 - Python", "tags": "boostcamp, python, level 1, week 1", "date": "2022-09-19 10:00:00 +0900", "snippet": " Variables Variable and Memory 변수 이름 작명법 기본 자료형 (Primitive Data Types) List 또는 Array 정의 indexing slicing 리스트 연산 메모리 저장 방식 패킹과 언패킹 이차원 리스트 Function &amp; Console I/O Function 함수의 개요 함수 수행 순서 Parameter vs Argument 함수 형태 콘솔창 입출력 Conditional() 조건문이란? 논리 키워드 사용: and, or, not Loop(반복문) 반복문이란? 반복의 제어: break, continue String 개요 1 byte의 메모리 공간??? 프로그램 언어에서 데이터 타입 문자열 특징 Advanced Function Concept 함수 호출 방식 개요 Scoping Rule (변수의 범위) Recursive Function (재귀함수) Function Type Hints Function docstring VariablesVariable and Memory 가장 기초적인 프로그래밍 문법 개념 데이터(값)을 저장하기 위한 메모리 공간의 프로그래밍상 이름 메모리에 저장하는 방식 변수는 메모리 주소를 가지고 있고 변수에 들어가는 값은 메모리 주소에 할당됨 컴퓨터의 구조 - 폰 노이만(John von Neumann) 아키텍처 폰 노이만 아키텍처에서는 사용자가 컴퓨터에 값을 입력하거나 프로그램을 실행할 경우 그 정보를 먼저 메모리에 저장시키고 CPU가 순차적으로 그 정보를 해석하고 계산하여 사용자에게 결과값을 전달한다. 변수 이름 작명법 알파벳, 숫자, 언더스코어(_)로 선언 가능 의미 있는 단어로 표기하면 좋다 대소문자가 구분된다 특별한 의미가 있는 예약어는 쓰지 않는다.기본 자료형 (Primitive Data Types) data type: 파이썬이 처리할 수 있는 데이터 유형. 메모리 공간을 차지하는지 데이터 타입마다 다름.List 또는 Array정의 시퀀스 자료형, 여러 데이터들의 집합 int, float 같은 다양한 데이터 타입 포함.indexing list에 있는 값들은 주소를 가짐 주소를 사용해 할당된 값을 호출. slicing list의 값들을 잘라서 쓰는 것이 슬라이싱 list의 주소 값을 기반으로 부분 값을 반환.리스트 연산 concatenate, in, append, extend, del, pop메모리 저장 방식 list는 다양한 data type이 하나의 list에 들어가도 됨 파이썬은 해당 리스트 변수에는 리스트 주소값이 저장됨.패킹과 언패킹 패킹: 한 변수에 여러 개의 데이터를 넣는 것 언패킹: 한 변수의 데이터를 가각의 변수로 반환.이차원 리스트 리스트 안에 리스트를 넣을 수 있음Function &amp; Console I/OFunction함수의 개요 어떤 일을 수행하는 코드의 덩어리 반복적인 수행을 1회만 작성 후 호출 코드를 논리적인 단위로 분리 (코드 = 하나의 보고서) 캡슐화: 인터페이스만 알면 타인의 코드 사용함수 수행 순서 함수 부분를 제외한 메인프로그램부터 시작 함수 호출 시 함수 부분을 수행 후 되돌아옴Parameter vs Argument parameter: 함수의 입력 값 인터페이스def f(x): return 2 * x + 7 argument: 실제 Parameter에 대입된 값print(f(2)) 함수 형태 parameter 유무, 반환 값(return value) 유무에 따라 함수의 형태가 다름   parameter 없음 parameter 존재 반환 값 없음 함수 내의 수행문만 수행 parameter를 사용, 수행문만 수행 반환 값 존재 parameter없이, 수행문 수행 후 결과값 반환 parameter를 사용하여 수행문 수행 후 결과값 반환 콘솔창 입출력 input함수는 콘솔창에서 문자열을 입력 받는 함수 print함수로 콘솔창에 데이터 출력.Conditional()조건문이란? 조건에 따라서 특벙한 동작을 하게하는 명령어 조건문은 조건을 나타내는 기준과 실행해야 할 명령으로 구성됨 조건의 참, 거짓에 따라 실행해야 할 명령이 수행되거나 되지 않음 파이썬은 조건문으로 if, else, elif을 사용한다 is연산자는 메모리 주소가 같아야 한다. 숫자열은 0이 아닌 숫자면, string에서는 존재하면 참이 된다.논리 키워드 사용: and, or, not 조건문을 표현할 때 집합의 논리 키워드를 함께 사용하여 참과 거짓을 판단하기도 함.Loop(반복문)반복문이란? 정해진 동작을 반복적으로 수행하게 하는 명령문 반복문은 반복 시작 조건, 종료 조건, 수행 명령으로 구성된다 파이썬은 반복문으로 for, while등의 명령 키워드를 사용한다.반복의 제어: break, continue break: 특정 조건에서 반복 종료 continue: 특정 조건에서 남은 반복 명령 skipString개요 시퀀스 자료형으로 문자형 data를 메모리에 저장. 영문자 한 글자는 1byte의 메모리 공간을 사용한다.1 byte의 메모리 공간??? 컴퓨터는 2진수로 데이터를 저장 이진수 한 자릿수는 1bit로 저장됨 즉 1 bit는 0 또는 1 1 byte = 9 bit = $2^8$ = 256 까지 저장 가능 컴퓨터는 문자를 직접적으로 인식 X 이를 위해 2진수를 문자로 변환하는 표준 규칙을 정함 이러한 규칙에 따라 문자를 2진수로 변환하여 저장하거나 저장된 2진수를 숫자로 변환하여 표시한다. 예) 대문자 U는 이진수로 “1000011” 변환됨 (UTF-8 기준) 프로그램 언어에서 데이터 타입 각 타입 별로 메모리 공간을 할당 받은 크기가 다름 메모리 공간에 따라 표현할 수 있는 숫자범위가 다름 데이터 타입은 메모리의 효율적 활용을 위해 매우 중요하다.문자열 특징 인덱싱 문자열의 각 문자는 개별 주소(offset)를 가짐 이 주소를 사용해 할당된 값을 가져오는 것이 인덱싱이라고 한다 list와 같은 형태로 데이터를 처리한다. 슬라이싱 문자열의 주소값을 기반으로 문자열의 부분값을 반환 raw string r'hello \\n works in raw string' Advanced Function Concept함수 호출 방식 개요 함수에서 parameter를 전달하는 방식 값에 의한 호출(Call by Value) 함수에서 parameter를 넘길 때 값만 넘긴다 참조의 의한 호출(Call by Reference) 함수에서 parameter를 넘길 때 메모리 주소를 넘긴다 객체 참조에 의한 호출(Call by Object Reference) 파이썬은 객체의 주소가 함수로 전달되는 방식을 사용한다 전달된 객체를 참조하여 변경 시 호출자에게 영향을 주나 새로운 객체를 만드면 호출자에게 영향을 주지 않는다. Scoping Rule (변수의 범위) 변수가 사용되는 범위 지역변수(local variable): 함수내에서만 사용 전역변수(Global variable): 프로그램 전체에 사용 함수 내에 전역변수랑 같은 이름의 변수를 선언하면 새로운 지역 변수가 생긴다 함수 내에서 전역변수 사용시 global 키워드를 사용하면 된다.Recursive Function (재귀함수) 자기자신을 호출하는 함수 재귀 종료 조건 존재하며 종료 조건까지 함수호출을 반복한다.Function Type Hints def type_hint_example(name: str) -&gt; str: return f\"Hello, {name}\" 사용자에게 인터페이스를 명확히 알려줄 수 있다 함수의 문서화시 parameter에 대한 정보를 명확히 알 수 있다 시스템 전체적인 안정성을 확보할 수 있다.Function docstring 파이썬 함수에 대한 상세스펙을 사전에 작성해서 사용자의 이행도를 증가한다 def add_binary(a, b): \"\"\" Returns the sum of two decimal numbers in binary digits. Parameters: a (int): A decimal integer b (int): Another decimal integer Return: binary_sum(str): Binary string of the sum of a and b \"\"\" binary_sum = bin(a+b)[2:] return binary_sum" }, { "title": "[boostcamp AI Tech][Python] Lecture 1: Intro. to Python", "url": "/posts/day-1-lecture-1/", "categories": "boostcamp AI Tech, Week 1 - Python", "tags": "boostcamp, python, level 1, week 1", "date": "2022-09-19 10:00:00 +0900", "snippet": " Basic Computer Class for Newbies 컴퓨터 OS 파일 시스템 파일과 디렉토리 절대 경로와 상대 경로 터미널 정의 기본 명령어 Python python의 시작 Why Python? Basic Computer Class for Newbies컴퓨터 OS Operating System, 운영체제 우리가 프로그램이 동작할 수 있는 구동 환경 하드웨어와 소프트웨어를 연결해주는 체제 어플리케이션은 운영체제에 dependent .exe 파일은 윈도우 전용 하지만 파이썬은 운영체제에 대해 독립적인 언어 파일 시스템 OS에서 파일을 저장하는 트리구조 저장 체계 root 디렉토리로 부터 시작하는 트리구조로 되어있음파일과 디렉토리파일의 기본 체계에는 파일과 디렉토리가 있다.디렉토리 (Directory) 폴더 또는 디렉토리로 불림 파일과 다른 디렉토리를 포함할 수 있음.파일 (File) 컴퓨터에서 정보를 저장하는 논리적인 단위 파일은 파일명과 확장자로 식별됨 (예: hello.py) 실행, 쓰기, 읽기 등을 할 수 있음.절대 경로와 상대 경로 경로 - 컴퓨터 파일의 고유한 위치, 트리구조상 노드의 연결 절대 경로: 루트 디렉토리부터 파일위치까지의 경로 상대 경로: 현재 있는 디렉토리부터 타깃 파일까지의 경로터미널정의 마우스가 아닌 키보드로 명령을 입력해서 프로그램 실행하는 Command Line Interface(CLI) Graphic User Interface(GUI)와 달리 text를 사용해서 컴퓨터에 명령을 입력하는 인터페이스 체계 Console = Terminal = CMD창기본 명령어 cd: 현재 디렉토리 이름을 보여주거나 바꿈 clear: clear screen cp: 하나 이상의 파일을 다른 위치로 복사 rm: 하나 이상의 파일을 지움 ls: 디렉토리에 있는 파일과 하위 디렉토리 목록을 보여줌.Pythonpython의 시작 1991년 귀도 반 로섬 (Guido van Rossum)이 발표 플랫폼 독립적 인터프리터 언어: 인터프리터(통역기)를 사용하는 언어 객체 지향(object-oriented): 실행 순서가 아닌 단위 모듈(객체) 중심으로 프로그램을 작성 하나의 객체는 어떤 목적을 달성하기 위한 행동(method)와 속성(attribute)을 가지고 있음 동적 타이핑(dynamically-typed) 언어: 프로그램이 실행하는 시점에 프로그램이 사용해야할 데이터에 대한 타입을 결정함 처음 C언어로 구현되었음. 컴파일러 vs. 인터프리터 프로그램의 동작 과정 Why Python? 문법이 이해하기가 쉽운 문법 사람의 시간이 기계의 시간보다 중요하다 다양한 라이브러리 무엇을 생각하든 그것을 구현할 수 있다 이미 널리 쓰이는… 어디에든 쓸 수 있는 언어 데이터 분석, AI에서는 파이썬이 거의 표준어이다." } ]
